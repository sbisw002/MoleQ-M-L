{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2e8667-747b-4f86-b8f7-3d37cd792fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saumya/.conda/envs/penny_skl/lib/python3.12/site-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.8.0 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter notebook. Call main() directly with parameters:\n",
      "  results = main(n_runs=2, n_epochs=50, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparison of Graph Equivariant vs Non-Equivariant QML for LiH Energy/Force Prediction\n",
    "\n",
    "This script runs both methods on LiH molecular data and compares their performance.\n",
    "All results are saved to an output directory for later analysis.\n",
    "\n",
    "Methods compared:\n",
    "1. Graph Equivariant QML - Uses SO(3) equivariant encoding with Heisenberg observable\n",
    "2. Non-Equivariant QML - Simple QNN with basic rotations\n",
    "\n",
    "Usage:\n",
    "    python run_comparison.py --n_runs 3 --n_epochs 100 --output_dir results\n",
    "\"\"\"\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# GRAPH EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class EquivariantQML:\n",
    "    \"\"\"\n",
    "    Graph Equivariant Quantum Machine Learning model for molecular properties.\n",
    "    Uses SO(3) equivariant encoding with Heisenberg Hamiltonian observable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=3, depth=6, blocks=2, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.blocks = blocks\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Pauli matrices\n",
    "        self.X = np.array([[0, 1], [1, 0]])\n",
    "        self.Y = np.array([[0, -1.0j], [1.0j, 0]])\n",
    "        self.Z = np.array([[1, 0], [0, -1]])\n",
    "        \n",
    "        self.sigmas = jnp.array(np.array([self.X, self.Y, self.Z]))\n",
    "        self.sigmas_sigmas = jnp.array(np.array([\n",
    "            np.kron(self.X, self.X),\n",
    "            np.kron(self.Y, self.Y),\n",
    "            np.kron(self.Z, self.Z)\n",
    "        ]))\n",
    "        \n",
    "        # Create device and circuit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the equivariant quantum circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        blocks = self.blocks\n",
    "        sigmas = self.sigmas\n",
    "        sigmas_sigmas = self.sigmas_sigmas\n",
    "        \n",
    "        # Heisenberg observable\n",
    "        Heisenberg = [\n",
    "            qml.PauliX(0) @ qml.PauliX(1),\n",
    "            qml.PauliY(0) @ qml.PauliY(1),\n",
    "            qml.PauliZ(0) @ qml.PauliZ(1),\n",
    "        ]\n",
    "        self.Observable = qml.Hamiltonian(np.ones((3)), Heisenberg)\n",
    "        \n",
    "        def singlet(wires):\n",
    "            qml.Hadamard(wires=wires[0])\n",
    "            qml.PauliZ(wires=wires[0])\n",
    "            qml.PauliX(wires=wires[1])\n",
    "            qml.CNOT(wires=wires)\n",
    "        \n",
    "        def equivariant_encoding(alpha, data, wires):\n",
    "            hamiltonian = jnp.einsum(\"i,ijk\", data, sigmas)\n",
    "            U = jax.scipy.linalg.expm(-1.0j * alpha * hamiltonian / 2)\n",
    "            qml.QubitUnitary(U, wires=wires, id=\"E\")\n",
    "        \n",
    "        def trainable_layer(weight, wires):\n",
    "            hamiltonian = jnp.einsum(\"ijk->jk\", sigmas_sigmas)\n",
    "            U = jax.scipy.linalg.expm(-1.0j * weight * hamiltonian)\n",
    "            qml.QubitUnitary(U, wires=wires, id=\"U\")\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\")\n",
    "        def circuit(data, params):\n",
    "            weights = params[\"params\"][\"weights\"]\n",
    "            alphas = params[\"params\"][\"alphas\"]\n",
    "            \n",
    "            # Initial entangled state\n",
    "            if num_qubits >= 2:\n",
    "                singlet(wires=[0, 1])\n",
    "            if num_qubits >= 3:\n",
    "                qml.CNOT(wires=[1, 2])\n",
    "            \n",
    "            # Initial encoding\n",
    "            for i in range(num_qubits):\n",
    "                equivariant_encoding(alphas[i, 0], jnp.asarray(data, dtype=complex)[i % 1, ...], wires=[i])\n",
    "            \n",
    "            # Layers\n",
    "            for d in range(depth):\n",
    "                qml.Barrier()\n",
    "                for b in range(blocks):\n",
    "                    for i in range(0, num_qubits - 1, 2):\n",
    "                        trainable_layer(weights[i, d + 1, b], wires=[i, (i + 1) % num_qubits])\n",
    "                    for i in range(1, num_qubits, 2):\n",
    "                        trainable_layer(weights[i, d + 1, b], wires=[i, (i + 1) % num_qubits])\n",
    "                \n",
    "                for i in range(num_qubits):\n",
    "                    equivariant_encoding(alphas[i, d + 1], jnp.asarray(data, dtype=complex)[i % 1, ...], wires=[i])\n",
    "            \n",
    "            return qml.expval(self.Observable)\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize trainable parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        limit = np.sqrt(1.0 / (self.num_qubits * self.depth))\n",
    "        weights = np.random.uniform(-limit, limit, (self.num_qubits, self.depth + 1, self.blocks))\n",
    "        \n",
    "        np.random.seed(self.seed + 1)\n",
    "        alphas = np.random.uniform(0.3, 0.8, (self.num_qubits, self.depth + 1))\n",
    "        \n",
    "        self.params = {\n",
    "            \"params\": {\n",
    "                \"weights\": jnp.array(weights),\n",
    "                \"alphas\": jnp.array(alphas),\n",
    "                \"epsilon\": None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NON-EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class NonEquivariantQML:\n",
    "    \"\"\"\n",
    "    Simple non-equivariant QNN for molecular properties.\n",
    "    Uses basic rotations without symmetry preservation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=4, depth=3, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the simple QNN circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            weights = params[\"weights\"]\n",
    "            \n",
    "            # Single feature: bond length\n",
    "            dist = jnp.linalg.norm(positions[1] - positions[0])\n",
    "            \n",
    "            # Initialize\n",
    "            for i in range(num_qubits):\n",
    "                qml.RY(0.5, wires=i)\n",
    "            \n",
    "            # Simple layers\n",
    "            for layer in range(depth):\n",
    "                for i in range(num_qubits):\n",
    "                    qml.RY(weights[layer, i, 0] * dist, wires=i)\n",
    "                \n",
    "                for i in range(num_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "                \n",
    "                for i in range(num_qubits):\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "                    qml.RY(weights[layer, i, 2], wires=i)\n",
    "            \n",
    "            return qml.expval(qml.PauliZ(0) + qml.PauliZ(1) + qml.PauliZ(2) + qml.PauliZ(3))\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        weights = np.random.normal(0, 0.1, (self.depth, self.num_qubits, 3))\n",
    "        self.params = {\"weights\": jnp.array(weights)}\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def train_equivariant(model, data_train, E_train, F_train, data_test, E_test, F_test,\n",
    "                      n_epochs=200, lr=0.01, lambda_E=1.5, lambda_F=2.0):\n",
    "    \"\"\"Train the equivariant model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def mse_loss(predictions, targets):\n",
    "        return jnp.mean((predictions - targets) ** 2)\n",
    "    \n",
    "    @jax.jit\n",
    "    def cost(params, data, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(data, params)\n",
    "        E_loss = mse_loss(E_pred, E_target)\n",
    "        \n",
    "        F_pred = vec_force(data, params)\n",
    "        F_loss = mse_loss(F_pred, F_target)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(cost, argnums=0, has_aux=True)(\n",
    "            get_params(opt_state), data_train, E_train, F_train\n",
    "        )\n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(data_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(data_test, test_params))\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_non_equivariant(model, pos_train, E_train, F_train, pos_test, E_test, F_test,\n",
    "                          n_epochs=200, lr=0.01, lambda_E=2.0, lambda_F=1.0):\n",
    "    \"\"\"Train the non-equivariant model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_z = F_pred_full[:, 1, 2]\n",
    "        F_loss = jnp.mean((F_pred_z - F_target) ** 2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), pos_train, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(pos_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(pos_test, test_params))[:, 1, 2]\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_lih_data(data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Load LiH molecular data.\"\"\"\n",
    "    energy = np.load(os.path.join(data_dir, \"Energy.npy\"))\n",
    "    forces = np.load(os.path.join(data_dir, \"Forces.npy\"))\n",
    "    positions = np.load(os.path.join(data_dir, \"Positions.npy\"))\n",
    "    \n",
    "    return energy, forces, positions\n",
    "\n",
    "\n",
    "def prepare_data(energy, forces, positions, test_split=0.2, seed=42):\n",
    "    \"\"\"Prepare and scale data for training.\"\"\"\n",
    "    shape = positions.shape\n",
    "    \n",
    "    # Scale energy\n",
    "    energy_scaler = MinMaxScaler((-1, 1))\n",
    "    if energy.ndim == 1:\n",
    "        energy = energy.reshape(-1, 1)\n",
    "    energy_scaled = energy_scaler.fit_transform(energy).flatten()\n",
    "    \n",
    "    # Center molecule positions\n",
    "    n_atoms_total = positions.shape[1]\n",
    "    positions_centered = np.zeros((shape[0], n_atoms_total - 1, 3))\n",
    "    positions_centered[:, 0, :] = positions[:, 1, :] - positions[:, 0, :]\n",
    "    \n",
    "    # Scale forces (z-component of H atom)\n",
    "    forces_H = forces[:, 1:, :]\n",
    "    force_scaler = MinMaxScaler((-1, 1))\n",
    "    forces_z_only = forces_H[:, 0, 2].reshape(-1, 1)\n",
    "    forces_z_scaled = force_scaler.fit_transform(forces_z_only).flatten()\n",
    "    \n",
    "    forces_scaled = np.zeros_like(forces_H)\n",
    "    forces_scaled[:, 0, 2] = forces_z_scaled\n",
    "    \n",
    "    # Train/test split\n",
    "    np.random.seed(seed)\n",
    "    n_samples = shape[0]\n",
    "    indices_train = np.random.choice(np.arange(n_samples), size=int((1-test_split) * n_samples), replace=False)\n",
    "    indices_test = np.setdiff1d(np.arange(n_samples), indices_train)\n",
    "    \n",
    "    data = {\n",
    "        \"energy_scaler\": energy_scaler,\n",
    "        \"force_scaler\": force_scaler,\n",
    "        \"energy_scaled\": energy_scaled,\n",
    "        \"forces_scaled\": forces_scaled,\n",
    "        \"positions_centered\": positions_centered,\n",
    "        \"positions_raw\": positions,\n",
    "        \"forces_H\": forces_H,\n",
    "        \"indices_train\": indices_train,\n",
    "        \"indices_test\": indices_test,\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, data, model_type=\"equivariant\"):\n",
    "    \"\"\"Evaluate model and compute metrics.\"\"\"\n",
    "    \n",
    "    positions_centered = data[\"positions_centered\"]\n",
    "    positions_raw = data[\"positions_raw\"]\n",
    "    energy_scaled = data[\"energy_scaled\"]\n",
    "    forces_z_scaled = data[\"forces_scaled\"][:, 0, 2]\n",
    "    energy_scaler = data[\"energy_scaler\"]\n",
    "    force_scaler = data[\"force_scaler\"]\n",
    "    indices_train = data[\"indices_train\"]\n",
    "    indices_test = data[\"indices_test\"]\n",
    "    forces_H = data[\"forces_H\"]\n",
    "    \n",
    "    if model_type == \"equivariant\":\n",
    "        # Get predictions\n",
    "        E_pred_scaled = np.array(model.vec_circuit(jnp.array(positions_centered), model.params))\n",
    "        \n",
    "        def energy_single(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(energy_single, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_pred_scaled = np.array(vec_force(jnp.array(positions_centered), model.params))\n",
    "        F_pred_z_scaled = F_pred_scaled[:, 0, 2]\n",
    "    else:\n",
    "        E_pred_scaled = np.array(model.vec_circuit(jnp.array(positions_raw), model.params))\n",
    "        \n",
    "        def energy_single(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(energy_single, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_pred_all = np.array(vec_force(jnp.array(positions_raw), model.params))\n",
    "        F_pred_z_scaled = F_pred_all[:, 1, 2]\n",
    "    \n",
    "    # Post-correction for energy\n",
    "    def corr_E(E, a, b, c):\n",
    "        return a * E**2 + b * E + c\n",
    "    \n",
    "    try:\n",
    "        popt_E, _ = curve_fit(corr_E, E_pred_scaled[indices_train], energy_scaled[indices_train])\n",
    "        E_pred_corrected = corr_E(E_pred_scaled, *popt_E)\n",
    "    except:\n",
    "        E_pred_corrected = E_pred_scaled\n",
    "    \n",
    "    # Post-correction for force\n",
    "    try:\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(F_pred_z_scaled[indices_train].reshape(-1, 1), forces_z_scaled[indices_train])\n",
    "        F_pred_corrected = lr_model.predict(F_pred_z_scaled.reshape(-1, 1)).flatten()\n",
    "    except:\n",
    "        F_pred_corrected = F_pred_z_scaled\n",
    "    \n",
    "    # Inverse transform\n",
    "    E_pred_original = energy_scaler.inverse_transform(E_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    F_pred_original = force_scaler.inverse_transform(F_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    E_true_original = energy_scaler.inverse_transform(energy_scaled.reshape(-1, 1)).flatten()\n",
    "    F_true_original = forces_H[:, 0, 2]\n",
    "    \n",
    "    # Compute metrics on test set\n",
    "    E_mae = np.mean(np.abs(E_pred_original[indices_test] - E_true_original[indices_test]))\n",
    "    E_rmse = np.sqrt(np.mean((E_pred_original[indices_test] - E_true_original[indices_test]) ** 2))\n",
    "    E_r2 = 1 - np.sum((E_pred_original[indices_test] - E_true_original[indices_test])**2) / \\\n",
    "               np.sum((E_true_original[indices_test] - E_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    F_mae = np.mean(np.abs(F_pred_original[indices_test] - F_true_original[indices_test]))\n",
    "    F_rmse = np.sqrt(np.mean((F_pred_original[indices_test] - F_true_original[indices_test]) ** 2))\n",
    "    F_r2 = 1 - np.sum((F_pred_original[indices_test] - F_true_original[indices_test])**2) / \\\n",
    "               np.sum((F_true_original[indices_test] - F_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    metrics = {\n",
    "        \"E_mae_Ha\": float(E_mae),\n",
    "        \"E_mae_eV\": float(E_mae * 27.2114),\n",
    "        \"E_rmse_Ha\": float(E_rmse),\n",
    "        \"E_rmse_eV\": float(E_rmse * 27.2114),\n",
    "        \"E_r2\": float(E_r2),\n",
    "        \"F_mae\": float(F_mae),\n",
    "        \"F_rmse\": float(F_rmse),\n",
    "        \"F_r2\": float(F_r2),\n",
    "    }\n",
    "    \n",
    "    predictions = {\n",
    "        \"E_pred\": E_pred_original.tolist(),\n",
    "        \"E_true\": E_true_original.tolist(),\n",
    "        \"F_pred\": F_pred_original.tolist(),\n",
    "        \"F_true\": F_true_original.tolist(),\n",
    "        \"indices_test\": indices_test.tolist(),\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "def run_comparison(n_runs=3, n_epochs=100, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Run comparison between equivariant and non-equivariant models.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"LiH Energy/Force Prediction: Equivariant vs Non-Equivariant QML\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    try:\n",
    "        energy, forces, positions = load_lih_data(data_dir)\n",
    "        print(f\"  Loaded {len(energy)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Data not found in {data_dir}\")\n",
    "        print(\"  Please ensure the LiH data files are available\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    data = prepare_data(energy, forces, positions)\n",
    "    print(f\"  Train: {len(data['indices_train'])}, Test: {len(data['indices_test'])}\")\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = {\n",
    "        \"config\": {\n",
    "            \"n_runs\": n_runs,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        },\n",
    "        \"equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"non_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "    }\n",
    "    \n",
    "    # Prepare training data\n",
    "    E_train = data[\"energy_scaled\"][data[\"indices_train\"]]\n",
    "    E_test = data[\"energy_scaled\"][data[\"indices_test\"]]\n",
    "    \n",
    "    # For equivariant model\n",
    "    data_train_eq = jnp.array(data[\"positions_centered\"][data[\"indices_train\"]])\n",
    "    data_test_eq = jnp.array(data[\"positions_centered\"][data[\"indices_test\"]])\n",
    "    F_train_eq = data[\"forces_scaled\"][data[\"indices_train\"]]\n",
    "    F_test_eq = data[\"forces_scaled\"][data[\"indices_test\"]]\n",
    "    \n",
    "    # For non-equivariant model\n",
    "    pos_train_neq = jnp.array(data[\"positions_raw\"][data[\"indices_train\"]])\n",
    "    pos_test_neq = jnp.array(data[\"positions_raw\"][data[\"indices_test\"]])\n",
    "    F_train_neq = data[\"forces_scaled\"][data[\"indices_train\"], 0, 2]\n",
    "    F_test_neq = data[\"forces_scaled\"][data[\"indices_test\"], 0, 2]\n",
    "    \n",
    "    # Run experiments\n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"RUN {run+1}/{n_runs}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        run_seed = 42 + run * 100\n",
    "        \n",
    "        # --- Equivariant Model ---\n",
    "        print(f\"\\n[Equivariant Model]\")\n",
    "        eq_model = EquivariantQML(num_qubits=3, depth=6, blocks=2, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        eq_history = train_equivariant(\n",
    "            eq_model, data_train_eq, E_train, F_train_eq,\n",
    "            data_test_eq, E_test, F_test_eq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        eq_metrics, eq_predictions = evaluate_model(eq_model, data, \"equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={eq_metrics['E_mae_Ha']:.6f} Ha, R²={eq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={eq_metrics['F_mae']:.4f} eV/Å, R²={eq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": eq_history,\n",
    "            \"metrics\": eq_metrics,\n",
    "            \"predictions\": eq_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- Non-Equivariant Model ---\n",
    "        print(f\"\\n[Non-Equivariant Model]\")\n",
    "        neq_model = NonEquivariantQML(num_qubits=4, depth=3, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        neq_history = train_non_equivariant(\n",
    "            neq_model, pos_train_neq, E_train, F_train_neq,\n",
    "            pos_test_neq, E_test, F_test_neq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        neq_metrics, neq_predictions = evaluate_model(neq_model, data, \"non_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={neq_metrics['E_mae_Ha']:.6f} Ha, R²={neq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={neq_metrics['F_mae']:.4f} eV/Å, R²={neq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"non_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": neq_history,\n",
    "            \"metrics\": neq_metrics,\n",
    "            \"predictions\": neq_predictions,\n",
    "        })\n",
    "    \n",
    "    # Compute summary statistics\n",
    "    for model_type in [\"equivariant\", \"non_equivariant\"]:\n",
    "        metrics_list = [r[\"metrics\"] for r in all_results[model_type][\"runs\"]]\n",
    "        \n",
    "        summary = {}\n",
    "        for key in metrics_list[0].keys():\n",
    "            values = [m[key] for m in metrics_list]\n",
    "            summary[key] = {\n",
    "                \"mean\": float(np.mean(values)),\n",
    "                \"std\": float(np.std(values)),\n",
    "                \"min\": float(np.min(values)),\n",
    "                \"max\": float(np.max(values)),\n",
    "                \"values\": values,\n",
    "            }\n",
    "        all_results[model_type][\"metrics_summary\"] = summary\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(output_dir, \"results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    # Save numpy arrays for easy loading\n",
    "    np.savez(os.path.join(output_dir, \"metrics.npz\"),\n",
    "             eq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             neq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"non_equivariant\"][\"runs\"]])\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Metric':<20} {'Equivariant':<25} {'Non-Equivariant':<25}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for metric in [\"E_r2\", \"E_mae_Ha\", \"F_r2\", \"F_mae\"]:\n",
    "        eq_mean = all_results[\"equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        eq_std = all_results[\"equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        neq_mean = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        neq_std = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        \n",
    "        print(f\"{metric:<20} {eq_mean:.4f} ± {eq_std:.4f}       {neq_mean:.4f} ± {neq_std:.4f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main(n_runs=2, n_epochs=50, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"\n",
    "    Main function - can be called directly from Jupyter or command line.\n",
    "    \n",
    "    Args:\n",
    "        n_runs: Number of runs for each model\n",
    "        n_epochs: Training epochs per run\n",
    "        output_dir: Directory to save results\n",
    "        data_dir: Directory containing LiH data (.npy files)\n",
    "    \n",
    "    Returns:\n",
    "        results dictionary\n",
    "    \"\"\"\n",
    "    return run_comparison(\n",
    "        n_runs=n_runs,\n",
    "        n_epochs=n_epochs,\n",
    "        output_dir=output_dir,\n",
    "        data_dir=data_dir\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Check if running in Jupyter\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Running in Jupyter - use defaults or call main() directly\n",
    "        print(\"Running in Jupyter notebook. Call main() directly with parameters:\")\n",
    "        print(\"  results = main(n_runs=2, n_epochs=50, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')\")\n",
    "    else:\n",
    "        # Running as script - use argparse\n",
    "        parser = argparse.ArgumentParser(description=\"Compare Equivariant vs Non-Equivariant QML on LiH\")\n",
    "        parser.add_argument(\"--n_runs\", type=int, default=2, help=\"Number of runs\")\n",
    "        parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"Training epochs per run\")\n",
    "        parser.add_argument(\"--output_dir\", type=str, default=\"lih_comparison_results\", help=\"Output directory\")\n",
    "        parser.add_argument(\"--data_dir\", type=str, default=\"eqnn_force_field_data_LiH\", help=\"Data directory\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        results = main(\n",
    "            n_runs=args.n_runs,\n",
    "            n_epochs=args.n_epochs,\n",
    "            output_dir=args.output_dir,\n",
    "            data_dir=args.data_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831e9223-4615-4835-83c5-91863217e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-11-30 03:38:16,789:jax._src.xla_bridge:850: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LiH Energy/Force Prediction: Equivariant vs Non-Equivariant QML\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loaded 2400 samples\n",
      "  Train: 1920, Test: 480\n",
      "\n",
      "======================================================================\n",
      "RUN 1/1\n",
      "======================================================================\n",
      "\n",
      "[Equivariant Model]\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.033382 Ha, R²=0.9966\n",
      "  Force:  MAE=3.2999 eV/Å, R²=0.9239\n",
      "\n",
      "[Non-Equivariant Model]\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.026232 Ha, R²=0.9979\n",
      "  Force:  MAE=2.5130 eV/Å, R²=0.9584\n",
      "\n",
      "Results saved to: lih_results/results.json\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Metric               Equivariant               Non-Equivariant          \n",
      "----------------------------------------------------------------------\n",
      "E_r2                 0.9966 ± 0.0000       0.9979 ± 0.0000\n",
      "E_mae_Ha             0.0334 ± 0.0000       0.0262 ± 0.0000\n",
      "F_r2                 0.9239 ± 0.0000       0.9584 ± 0.0000\n",
      "F_mae                3.2999 ± 0.0000       2.5130 ± 0.0000\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "results = main(n_runs=1, n_epochs=200, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76c796-d49d-4e77-b24a-06e5a3d4c5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf23a076-d35e-4a69-a0a7-7d40780e8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparison of Graph Equivariant vs Non-Equivariant QML for LiH Energy/Force Prediction\n",
    "\n",
    "This script runs both methods on LiH molecular data and compares their performance.\n",
    "All results are saved to an output directory for later analysis.\n",
    "\n",
    "Methods compared:\n",
    "1. Rotationally Equivariant QML - Uses SO(3) equivariant encoding with Heisenberg observable\n",
    "2. Graph Embedding Equivariant QML - Simple QNN with basic rotations\n",
    "\n",
    "Usage:\n",
    "    python run_comparison.py --n_runs 3 --n_epochs 100 --output_dir results\n",
    "\"\"\"\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# ROTATIONALLY EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class EquivariantQML:\n",
    "    \"\"\"\n",
    "    Rotationally Equivariant Quantum Machine Learning model for molecular properties.\n",
    "    Uses SO(3) equivariant encoding with Heisenberg Hamiltonian observable.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=3, depth=6, blocks=2, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.blocks = blocks\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Pauli matrices\n",
    "        self.X = np.array([[0, 1], [1, 0]])\n",
    "        self.Y = np.array([[0, -1.0j], [1.0j, 0]])\n",
    "        self.Z = np.array([[1, 0], [0, -1]])\n",
    "        \n",
    "        self.sigmas = jnp.array(np.array([self.X, self.Y, self.Z]))\n",
    "        self.sigmas_sigmas = jnp.array(np.array([\n",
    "            np.kron(self.X, self.X),\n",
    "            np.kron(self.Y, self.Y),\n",
    "            np.kron(self.Z, self.Z)\n",
    "        ]))\n",
    "        \n",
    "        # Create device and circuit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the equivariant quantum circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        blocks = self.blocks\n",
    "        sigmas = self.sigmas\n",
    "        sigmas_sigmas = self.sigmas_sigmas\n",
    "        \n",
    "        # Heisenberg observable\n",
    "        Heisenberg = [\n",
    "            qml.PauliX(0) @ qml.PauliX(1),\n",
    "            qml.PauliY(0) @ qml.PauliY(1),\n",
    "            qml.PauliZ(0) @ qml.PauliZ(1),\n",
    "        ]\n",
    "        self.Observable = qml.Hamiltonian(np.ones((3)), Heisenberg)\n",
    "        \n",
    "        def singlet(wires):\n",
    "            qml.Hadamard(wires=wires[0])\n",
    "            qml.PauliZ(wires=wires[0])\n",
    "            qml.PauliX(wires=wires[1])\n",
    "            qml.CNOT(wires=wires)\n",
    "        \n",
    "        def equivariant_encoding(alpha, data, wires):\n",
    "            hamiltonian = jnp.einsum(\"i,ijk\", data, sigmas)\n",
    "            U = jax.scipy.linalg.expm(-1.0j * alpha * hamiltonian / 2)\n",
    "            qml.QubitUnitary(U, wires=wires, id=\"E\")\n",
    "        \n",
    "        def trainable_layer(weight, wires):\n",
    "            hamiltonian = jnp.einsum(\"ijk->jk\", sigmas_sigmas)\n",
    "            U = jax.scipy.linalg.expm(-1.0j * weight * hamiltonian)\n",
    "            qml.QubitUnitary(U, wires=wires, id=\"U\")\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\")\n",
    "        def circuit(data, params):\n",
    "            weights = params[\"params\"][\"weights\"]\n",
    "            alphas = params[\"params\"][\"alphas\"]\n",
    "            \n",
    "            # Initial entangled state\n",
    "            if num_qubits >= 2:\n",
    "                singlet(wires=[0, 1])\n",
    "            if num_qubits >= 3:\n",
    "                qml.CNOT(wires=[1, 2])\n",
    "            \n",
    "            # Initial encoding\n",
    "            for i in range(num_qubits):\n",
    "                equivariant_encoding(alphas[i, 0], jnp.asarray(data, dtype=complex)[i % 1, ...], wires=[i])\n",
    "            \n",
    "            # Layers\n",
    "            for d in range(depth):\n",
    "                qml.Barrier()\n",
    "                for b in range(blocks):\n",
    "                    for i in range(0, num_qubits - 1, 2):\n",
    "                        trainable_layer(weights[i, d + 1, b], wires=[i, (i + 1) % num_qubits])\n",
    "                    for i in range(1, num_qubits, 2):\n",
    "                        trainable_layer(weights[i, d + 1, b], wires=[i, (i + 1) % num_qubits])\n",
    "                \n",
    "                for i in range(num_qubits):\n",
    "                    equivariant_encoding(alphas[i, d + 1], jnp.asarray(data, dtype=complex)[i % 1, ...], wires=[i])\n",
    "            \n",
    "            return qml.expval(self.Observable)\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize trainable parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        limit = np.sqrt(1.0 / (self.num_qubits * self.depth))\n",
    "        weights = np.random.uniform(-limit, limit, (self.num_qubits, self.depth + 1, self.blocks))\n",
    "        \n",
    "        np.random.seed(self.seed + 1)\n",
    "        alphas = np.random.uniform(0.3, 0.8, (self.num_qubits, self.depth + 1))\n",
    "        \n",
    "        self.params = {\n",
    "            \"params\": {\n",
    "                \"weights\": jnp.array(weights),\n",
    "                \"alphas\": jnp.array(alphas),\n",
    "                \"epsilon\": None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GRAPH EMBEDDING EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class NonEquivariantQML:\n",
    "    \"\"\"\n",
    "    Graph Embedding Equivariant QNN for molecular properties.\n",
    "    Uses basic rotations without symmetry preservation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=4, depth=3, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the simple QNN circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            weights = params[\"weights\"]\n",
    "            \n",
    "            # Single feature: bond length\n",
    "            dist = jnp.linalg.norm(positions[1] - positions[0])\n",
    "            \n",
    "            # Initialize\n",
    "            for i in range(num_qubits):\n",
    "                qml.RY(0.5, wires=i)\n",
    "            \n",
    "            # Simple layers\n",
    "            for layer in range(depth):\n",
    "                for i in range(num_qubits):\n",
    "                    qml.RY(weights[layer, i, 0] * dist, wires=i)\n",
    "                \n",
    "                for i in range(num_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "                \n",
    "                for i in range(num_qubits):\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "                    qml.RY(weights[layer, i, 2], wires=i)\n",
    "            \n",
    "            return qml.expval(qml.PauliZ(0) + qml.PauliZ(1) + qml.PauliZ(2) + qml.PauliZ(3))\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        weights = np.random.normal(0, 0.1, (self.depth, self.num_qubits, 3))\n",
    "        self.params = {\"weights\": jnp.array(weights)}\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def train_equivariant(model, data_train, E_train, F_train, data_test, E_test, F_test,\n",
    "                      n_epochs=200, lr=0.01, lambda_E=1.5, lambda_F=2.0):\n",
    "    \"\"\"Train the equivariant model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def mse_loss(predictions, targets):\n",
    "        return jnp.mean((predictions - targets) ** 2)\n",
    "    \n",
    "    @jax.jit\n",
    "    def cost(params, data, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(data, params)\n",
    "        E_loss = mse_loss(E_pred, E_target)\n",
    "        \n",
    "        F_pred = vec_force(data, params)\n",
    "        F_loss = mse_loss(F_pred, F_target)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(cost, argnums=0, has_aux=True)(\n",
    "            get_params(opt_state), data_train, E_train, F_train\n",
    "        )\n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(data_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(data_test, test_params))\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_non_equivariant(model, pos_train, E_train, F_train, pos_test, E_test, F_test,\n",
    "                          n_epochs=200, lr=0.01, lambda_E=2.0, lambda_F=1.0):\n",
    "    \"\"\"Train the non-equivariant model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_z = F_pred_full[:, 1, 2]\n",
    "        F_loss = jnp.mean((F_pred_z - F_target) ** 2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), pos_train, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(pos_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(pos_test, test_params))[:, 1, 2]\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_lih_data(data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Load LiH molecular data.\"\"\"\n",
    "    energy = np.load(os.path.join(data_dir, \"Energy.npy\"))\n",
    "    forces = np.load(os.path.join(data_dir, \"Forces.npy\"))\n",
    "    positions = np.load(os.path.join(data_dir, \"Positions.npy\"))\n",
    "    \n",
    "    return energy, forces, positions\n",
    "\n",
    "\n",
    "def prepare_data(energy, forces, positions, test_split=0.2, seed=42):\n",
    "    \"\"\"Prepare and scale data for training.\"\"\"\n",
    "    shape = positions.shape\n",
    "    \n",
    "    # Scale energy\n",
    "    energy_scaler = MinMaxScaler((-1, 1))\n",
    "    if energy.ndim == 1:\n",
    "        energy = energy.reshape(-1, 1)\n",
    "    energy_scaled = energy_scaler.fit_transform(energy).flatten()\n",
    "    \n",
    "    # Center molecule positions\n",
    "    n_atoms_total = positions.shape[1]\n",
    "    positions_centered = np.zeros((shape[0], n_atoms_total - 1, 3))\n",
    "    positions_centered[:, 0, :] = positions[:, 1, :] - positions[:, 0, :]\n",
    "    \n",
    "    # Scale forces (z-component of H atom)\n",
    "    forces_H = forces[:, 1:, :]\n",
    "    force_scaler = MinMaxScaler((-1, 1))\n",
    "    forces_z_only = forces_H[:, 0, 2].reshape(-1, 1)\n",
    "    forces_z_scaled = force_scaler.fit_transform(forces_z_only).flatten()\n",
    "    \n",
    "    forces_scaled = np.zeros_like(forces_H)\n",
    "    forces_scaled[:, 0, 2] = forces_z_scaled\n",
    "    \n",
    "    # Train/test split\n",
    "    np.random.seed(seed)\n",
    "    n_samples = shape[0]\n",
    "    indices_train = np.random.choice(np.arange(n_samples), size=int((1-test_split) * n_samples), replace=False)\n",
    "    indices_test = np.setdiff1d(np.arange(n_samples), indices_train)\n",
    "    \n",
    "    data = {\n",
    "        \"energy_scaler\": energy_scaler,\n",
    "        \"force_scaler\": force_scaler,\n",
    "        \"energy_scaled\": energy_scaled,\n",
    "        \"forces_scaled\": forces_scaled,\n",
    "        \"positions_centered\": positions_centered,\n",
    "        \"positions_raw\": positions,\n",
    "        \"forces_H\": forces_H,\n",
    "        \"indices_train\": indices_train,\n",
    "        \"indices_test\": indices_test,\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, data, model_type=\"equivariant\"):\n",
    "    \"\"\"Evaluate model and compute metrics.\"\"\"\n",
    "    \n",
    "    positions_centered = data[\"positions_centered\"]\n",
    "    positions_raw = data[\"positions_raw\"]\n",
    "    energy_scaled = data[\"energy_scaled\"]\n",
    "    forces_z_scaled = data[\"forces_scaled\"][:, 0, 2]\n",
    "    energy_scaler = data[\"energy_scaler\"]\n",
    "    force_scaler = data[\"force_scaler\"]\n",
    "    indices_train = data[\"indices_train\"]\n",
    "    indices_test = data[\"indices_test\"]\n",
    "    forces_H = data[\"forces_H\"]\n",
    "    \n",
    "    if model_type == \"equivariant\":\n",
    "        # Get predictions\n",
    "        E_pred_scaled = np.array(model.vec_circuit(jnp.array(positions_centered), model.params))\n",
    "        \n",
    "        def energy_single(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(energy_single, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_pred_scaled = np.array(vec_force(jnp.array(positions_centered), model.params))\n",
    "        F_pred_z_scaled = F_pred_scaled[:, 0, 2]\n",
    "    else:\n",
    "        E_pred_scaled = np.array(model.vec_circuit(jnp.array(positions_raw), model.params))\n",
    "        \n",
    "        def energy_single(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(energy_single, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_pred_all = np.array(vec_force(jnp.array(positions_raw), model.params))\n",
    "        F_pred_z_scaled = F_pred_all[:, 1, 2]\n",
    "    \n",
    "    # Post-correction for energy\n",
    "    def corr_E(E, a, b, c):\n",
    "        return a * E**2 + b * E + c\n",
    "    \n",
    "    try:\n",
    "        popt_E, _ = curve_fit(corr_E, E_pred_scaled[indices_train], energy_scaled[indices_train])\n",
    "        E_pred_corrected = corr_E(E_pred_scaled, *popt_E)\n",
    "    except:\n",
    "        E_pred_corrected = E_pred_scaled\n",
    "    \n",
    "    # Post-correction for force\n",
    "    try:\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(F_pred_z_scaled[indices_train].reshape(-1, 1), forces_z_scaled[indices_train])\n",
    "        F_pred_corrected = lr_model.predict(F_pred_z_scaled.reshape(-1, 1)).flatten()\n",
    "    except:\n",
    "        F_pred_corrected = F_pred_z_scaled\n",
    "    \n",
    "    # Inverse transform\n",
    "    E_pred_original = energy_scaler.inverse_transform(E_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    F_pred_original = force_scaler.inverse_transform(F_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    E_true_original = energy_scaler.inverse_transform(energy_scaled.reshape(-1, 1)).flatten()\n",
    "    F_true_original = forces_H[:, 0, 2]\n",
    "    \n",
    "    # Compute metrics on test set\n",
    "    E_mae = np.mean(np.abs(E_pred_original[indices_test] - E_true_original[indices_test]))\n",
    "    E_rmse = np.sqrt(np.mean((E_pred_original[indices_test] - E_true_original[indices_test]) ** 2))\n",
    "    E_r2 = 1 - np.sum((E_pred_original[indices_test] - E_true_original[indices_test])**2) / \\\n",
    "               np.sum((E_true_original[indices_test] - E_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    F_mae = np.mean(np.abs(F_pred_original[indices_test] - F_true_original[indices_test]))\n",
    "    F_rmse = np.sqrt(np.mean((F_pred_original[indices_test] - F_true_original[indices_test]) ** 2))\n",
    "    F_r2 = 1 - np.sum((F_pred_original[indices_test] - F_true_original[indices_test])**2) / \\\n",
    "               np.sum((F_true_original[indices_test] - F_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    metrics = {\n",
    "        \"E_mae_Ha\": float(E_mae),\n",
    "        \"E_mae_eV\": float(E_mae * 27.2114),\n",
    "        \"E_rmse_Ha\": float(E_rmse),\n",
    "        \"E_rmse_eV\": float(E_rmse * 27.2114),\n",
    "        \"E_r2\": float(E_r2),\n",
    "        \"F_mae\": float(F_mae),\n",
    "        \"F_rmse\": float(F_rmse),\n",
    "        \"F_r2\": float(F_r2),\n",
    "    }\n",
    "    \n",
    "    predictions = {\n",
    "        \"E_pred\": E_pred_original.tolist(),\n",
    "        \"E_true\": E_true_original.tolist(),\n",
    "        \"F_pred\": F_pred_original.tolist(),\n",
    "        \"F_true\": F_true_original.tolist(),\n",
    "        \"indices_test\": indices_test.tolist(),\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "def run_comparison(n_runs=3, n_epochs=100, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Run comparison between equivariant and non-equivariant models.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"LiH Energy/Force Prediction: Rotationally Equivariant vs Graph Embedding Equivariant QML\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    try:\n",
    "        energy, forces, positions = load_lih_data(data_dir)\n",
    "        print(f\"  Loaded {len(energy)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Data not found in {data_dir}\")\n",
    "        print(\"  Please ensure the LiH data files are available\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    data = prepare_data(energy, forces, positions)\n",
    "    print(f\"  Train: {len(data['indices_train'])}, Test: {len(data['indices_test'])}\")\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = {\n",
    "        \"config\": {\n",
    "            \"n_runs\": n_runs,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        },\n",
    "        \"equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"non_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "    }\n",
    "    \n",
    "    # Prepare training data\n",
    "    E_train = data[\"energy_scaled\"][data[\"indices_train\"]]\n",
    "    E_test = data[\"energy_scaled\"][data[\"indices_test\"]]\n",
    "    \n",
    "    # For equivariant model\n",
    "    data_train_eq = jnp.array(data[\"positions_centered\"][data[\"indices_train\"]])\n",
    "    data_test_eq = jnp.array(data[\"positions_centered\"][data[\"indices_test\"]])\n",
    "    F_train_eq = data[\"forces_scaled\"][data[\"indices_train\"]]\n",
    "    F_test_eq = data[\"forces_scaled\"][data[\"indices_test\"]]\n",
    "    \n",
    "    # For non-equivariant model\n",
    "    pos_train_neq = jnp.array(data[\"positions_raw\"][data[\"indices_train\"]])\n",
    "    pos_test_neq = jnp.array(data[\"positions_raw\"][data[\"indices_test\"]])\n",
    "    F_train_neq = data[\"forces_scaled\"][data[\"indices_train\"], 0, 2]\n",
    "    F_test_neq = data[\"forces_scaled\"][data[\"indices_test\"], 0, 2]\n",
    "    \n",
    "    # Run experiments\n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"RUN {run+1}/{n_runs}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        run_seed = 42 + run * 100\n",
    "        \n",
    "        # --- Rotationally Equivariant Model ---\n",
    "        print(f\"\\n[Rotationally Equivariant QML]\")\n",
    "        eq_model = EquivariantQML(num_qubits=3, depth=6, blocks=2, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        eq_history = train_equivariant(\n",
    "            eq_model, data_train_eq, E_train, F_train_eq,\n",
    "            data_test_eq, E_test, F_test_eq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        eq_metrics, eq_predictions = evaluate_model(eq_model, data, \"equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={eq_metrics['E_mae_Ha']:.6f} Ha, R²={eq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={eq_metrics['F_mae']:.4f} eV/Å, R²={eq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": eq_history,\n",
    "            \"metrics\": eq_metrics,\n",
    "            \"predictions\": eq_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- Graph Embedding Equivariant Model ---\n",
    "        print(f\"\\n[Graph Embedding Equivariant QML]\")\n",
    "        neq_model = NonEquivariantQML(num_qubits=4, depth=3, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        neq_history = train_non_equivariant(\n",
    "            neq_model, pos_train_neq, E_train, F_train_neq,\n",
    "            pos_test_neq, E_test, F_test_neq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        neq_metrics, neq_predictions = evaluate_model(neq_model, data, \"non_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={neq_metrics['E_mae_Ha']:.6f} Ha, R²={neq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={neq_metrics['F_mae']:.4f} eV/Å, R²={neq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"non_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": neq_history,\n",
    "            \"metrics\": neq_metrics,\n",
    "            \"predictions\": neq_predictions,\n",
    "        })\n",
    "    \n",
    "    # Compute summary statistics\n",
    "    for model_type in [\"equivariant\", \"non_equivariant\"]:\n",
    "        metrics_list = [r[\"metrics\"] for r in all_results[model_type][\"runs\"]]\n",
    "        \n",
    "        summary = {}\n",
    "        for key in metrics_list[0].keys():\n",
    "            values = [m[key] for m in metrics_list]\n",
    "            summary[key] = {\n",
    "                \"mean\": float(np.mean(values)),\n",
    "                \"std\": float(np.std(values)),\n",
    "                \"min\": float(np.min(values)),\n",
    "                \"max\": float(np.max(values)),\n",
    "                \"values\": values,\n",
    "            }\n",
    "        all_results[model_type][\"metrics_summary\"] = summary\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(output_dir, \"results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    # Save numpy arrays for easy loading\n",
    "    np.savez(os.path.join(output_dir, \"metrics.npz\"),\n",
    "             eq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             eq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"equivariant\"][\"runs\"]],\n",
    "             neq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"non_equivariant\"][\"runs\"]])\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Metric':<20} {'Rotationally Equivariant QML':<30} {'Graph Embedding Equivariant QML':<30}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for metric in [\"E_r2\", \"E_mae_Ha\", \"F_r2\", \"F_mae\"]:\n",
    "        eq_mean = all_results[\"equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        eq_std = all_results[\"equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        neq_mean = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        neq_std = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        \n",
    "        print(f\"{metric:<20} {eq_mean:.4f} ± {eq_std:.4f}            {neq_mean:.4f} ± {neq_std:.4f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main(n_runs=2, n_epochs=50, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"\n",
    "    Main function - can be called directly from Jupyter or command line.\n",
    "    \n",
    "    Args:\n",
    "        n_runs: Number of runs for each model\n",
    "        n_epochs: Training epochs per run\n",
    "        output_dir: Directory to save results\n",
    "        data_dir: Directory containing LiH data (.npy files)\n",
    "    \n",
    "    Returns:\n",
    "        results dictionary\n",
    "    \"\"\"\n",
    "    return run_comparison(\n",
    "        n_runs=n_runs,\n",
    "        n_epochs=n_epochs,\n",
    "        output_dir=output_dir,\n",
    "        data_dir=data_dir\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Check if running in Jupyter\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        # Running in Jupyter - use defaults or call main() directly\n",
    "        print(\"Running in Jupyter notebook. Call main() directly with parameters:\")\n",
    "        print(\"  results = main(n_runs=2, n_epochs=50, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')\")\n",
    "    else:\n",
    "        # Running as script - use argparse\n",
    "        parser = argparse.ArgumentParser(description=\"Compare Rotationally Equivariant vs Graph Embedding Equivariant QML on LiH\")\n",
    "        parser.add_argument(\"--n_runs\", type=int, default=2, help=\"Number of runs\")\n",
    "        parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"Training epochs per run\")\n",
    "        parser.add_argument(\"--output_dir\", type=str, default=\"lih_comparison_results\", help=\"Output directory\")\n",
    "        parser.add_argument(\"--data_dir\", type=str, default=\"eqnn_force_field_data_LiH\", help=\"Data directory\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        results = main(\n",
    "            n_runs=args.n_runs,\n",
    "            n_epochs=args.n_epochs,\n",
    "            output_dir=args.output_dir,\n",
    "            data_dir=args.data_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac7b56b-1b28-4826-8ca2-724fe17a9ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LiH Energy/Force Prediction: Equivariant vs Non-Equivariant QML\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loaded 2400 samples\n",
      "  Train: 1920, Test: 480\n",
      "\n",
      "======================================================================\n",
      "RUN 1/1\n",
      "======================================================================\n",
      "\n",
      "[Equivariant Model]\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.033382 Ha, R²=0.9966\n",
      "  Force:  MAE=3.2999 eV/Å, R²=0.9239\n",
      "\n",
      "[Non-Equivariant Model]\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.026232 Ha, R²=0.9979\n",
      "  Force:  MAE=2.5130 eV/Å, R²=0.9584\n",
      "\n",
      "Results saved to: lih_results/results.json\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Metric               Equivariant               Non-Equivariant          \n",
      "----------------------------------------------------------------------\n",
      "E_r2                 0.9966 ± 0.0000       0.9979 ± 0.0000\n",
      "E_mae_Ha             0.0334 ± 0.0000       0.0262 ± 0.0000\n",
      "F_r2                 0.9239 ± 0.0000       0.9584 ± 0.0000\n",
      "F_mae                3.2999 ± 0.0000       2.5130 ± 0.0000\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "results = main(n_runs=1, n_epochs=200, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103f415-d4c4-46f9-98d7-302d6cf1baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
