{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2879b090-05f3-43e1-9255-5f7ee2399fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/10000 | Loss: 323.620860\n",
      "Epoch 400/10000 | Loss: 368.923889\n",
      "Epoch 600/10000 | Loss: 405.270325\n",
      "Epoch 800/10000 | Loss: 326.677053\n",
      "Epoch 1000/10000 | Loss: 384.755849\n",
      "Epoch 1200/10000 | Loss: 400.796010\n",
      "Epoch 1400/10000 | Loss: 423.364889\n",
      "Epoch 1600/10000 | Loss: 420.909078\n",
      "Epoch 1800/10000 | Loss: 420.817973\n",
      "Epoch 2000/10000 | Loss: 420.815216\n",
      "Epoch 2200/10000 | Loss: 420.816488\n",
      "Epoch 2400/10000 | Loss: 420.818064\n",
      "Epoch 2600/10000 | Loss: 420.815165\n",
      "Epoch 2800/10000 | Loss: 420.813334\n",
      "Epoch 3000/10000 | Loss: 420.814860\n",
      "Epoch 3200/10000 | Loss: 420.813273\n",
      "Epoch 3400/10000 | Loss: 420.813304\n",
      "Epoch 3600/10000 | Loss: 420.814596\n",
      "Epoch 3800/10000 | Loss: 420.813273\n",
      "Epoch 4000/10000 | Loss: 420.813507\n",
      "Epoch 4200/10000 | Loss: 420.816050\n",
      "Epoch 4400/10000 | Loss: 420.813232\n",
      "Epoch 4600/10000 | Loss: 420.814290\n",
      "Epoch 4800/10000 | Loss: 420.813243\n",
      "Epoch 5000/10000 | Loss: 420.816294\n",
      "Epoch 5200/10000 | Loss: 420.818960\n",
      "Epoch 5400/10000 | Loss: 420.813375\n",
      "Epoch 5600/10000 | Loss: 420.815002\n",
      "Epoch 5800/10000 | Loss: 420.814097\n",
      "Epoch 6000/10000 | Loss: 420.816091\n",
      "Epoch 6200/10000 | Loss: 420.813812\n",
      "Epoch 6400/10000 | Loss: 420.815745\n",
      "Epoch 6600/10000 | Loss: 420.816193\n",
      "Epoch 6800/10000 | Loss: 420.813304\n",
      "Epoch 7000/10000 | Loss: 420.813538\n",
      "Epoch 7200/10000 | Loss: 420.814026\n",
      "Epoch 7400/10000 | Loss: 420.814443\n",
      "Epoch 7600/10000 | Loss: 420.814443\n",
      "Epoch 7800/10000 | Loss: 420.816081\n",
      "Epoch 8000/10000 | Loss: 420.816294\n",
      "Epoch 8200/10000 | Loss: 420.813883\n",
      "Epoch 8400/10000 | Loss: 420.814128\n",
      "Epoch 8600/10000 | Loss: 420.813243\n",
      "Epoch 8800/10000 | Loss: 420.814677\n",
      "Epoch 9000/10000 | Loss: 420.817169\n",
      "Epoch 9200/10000 | Loss: 420.813466\n",
      "Epoch 9400/10000 | Loss: 420.814117\n",
      "Epoch 9600/10000 | Loss: 420.816132\n",
      "Epoch 9800/10000 | Loss: 420.813304\n",
      "Epoch 10000/10000 | Loss: 420.813700\n",
      "\n",
      "✅ Prediction complete!\n",
      "Energy MAE: 0.448257\n",
      "Force MAE:  10.582637\n",
      "\n",
      "First sample:\n",
      "Predicted energy: [-0.96935403]\n",
      "True energy:      [-0.9647689]\n",
      "Predicted forces:\n",
      " [[ -0.       -0.      -19.37458]\n",
      " [ -0.       -0.       19.37458]]\n",
      "True forces:\n",
      " [[ 5.2005502e-31 -5.2005502e-31 -1.9374767e+01]\n",
      " [-5.2005502e-31  5.2005502e-31  1.9374767e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load LiH dataset\n",
    "# -------------------------\n",
    "positions = np.load(\"eqnn_force_field_data/Positions.npy\")  # shape (N, 2, 3)\n",
    "forces = np.load(\"eqnn_force_field_data/Forces.npy\")        # shape (N, 2, 3)\n",
    "energy = np.load(\"eqnn_force_field_data/Energy.npy\")        # shape (N,)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Preprocessing\n",
    "# -------------------------\n",
    "energy = energy.reshape(-1, 1)\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "energy_scaled = scaler.fit_transform(energy).flatten()\n",
    "forces_scaled = forces * scaler.scale_[0]\n",
    "positions_centered = positions - positions[:, 0:1, :]  # place first atom at origin\n",
    "\n",
    "# Convert to torch tensors\n",
    "positions_tensor = torch.tensor(positions_centered, dtype=torch.float32)\n",
    "forces_tensor = torch.tensor(forces_scaled, dtype=torch.float32)\n",
    "energy_tensor = torch.tensor(energy_scaled, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# -------------------------\n",
    "# 3. EQNN Model\n",
    "# -------------------------\n",
    "class EQNN(nn.Module):\n",
    "    def __init__(self, num_atoms=2, hidden_dim=64):\n",
    "        super(EQNN, self).__init__()\n",
    "        self.num_atoms = num_atoms\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_atoms*(num_atoms-1)//2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, positions):\n",
    "        \"\"\"\n",
    "        positions: (batch, num_atoms, 3) with requires_grad=True\n",
    "        Returns: energy (batch,1), forces (batch,num_atoms,3)\n",
    "        \"\"\"\n",
    "        batch_size = positions.shape[0]\n",
    "        # Differentiable pairwise distances\n",
    "        dists = []\n",
    "        for i in range(self.num_atoms):\n",
    "            for j in range(i+1, self.num_atoms):\n",
    "                diff = positions[:, i:i+1, :] - positions[:, j:j+1, :]  # (batch,1,3)\n",
    "                dist = torch.sqrt(torch.sum(diff**2, dim=-1, keepdim=True))  # (batch,1,1)\n",
    "                dists.append(dist)\n",
    "        dists = torch.cat(dists, dim=1)  # (batch, num_pairs, 1)\n",
    "        dists = dists.squeeze(-1)        # (batch, num_pairs)\n",
    "\n",
    "        # Predict energy\n",
    "        energy = self.mlp(dists)\n",
    "\n",
    "        # Compute forces: -dE/dR\n",
    "        forces = -torch.autograd.grad(\n",
    "            energy.sum(), positions, create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return energy, forces\n",
    "\n",
    "# -------------------------\n",
    "# 4. Training setup\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "eqnn_model = EQNN(num_atoms=positions_tensor.shape[1], hidden_dim=64).to(device)\n",
    "optimizer = torch.optim.Adam(eqnn_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 10000\n",
    "batch_size = 8\n",
    "N = positions_tensor.shape[0]\n",
    "\n",
    "# -------------------------\n",
    "# 5. Training loop\n",
    "# -------------------------\n",
    "eqnn_model.train()\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(N)\n",
    "    total_loss = 0.0\n",
    "    for i in range(0, N, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        pos_batch = positions_tensor[idx].to(device)\n",
    "        e_batch = energy_tensor[idx].to(device)\n",
    "        f_batch = forces_tensor[idx].to(device)\n",
    "\n",
    "        # Crucial: positions must require grad for forces\n",
    "        pos_batch.requires_grad_(True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        e_pred, f_pred = eqnn_model(pos_batch)\n",
    "        loss = loss_fn(e_pred, e_batch) + loss_fn(f_pred, f_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/(N//batch_size):.6f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 6. Prediction / Testing\n",
    "# -------------------------\n",
    "eqnn_model.eval()\n",
    "pos_batch = positions_tensor.to(device)\n",
    "pos_batch.requires_grad_(True)  # needed for autograd forces\n",
    "energy_preds, force_preds = eqnn_model(pos_batch)\n",
    "energy_preds = energy_preds.detach().cpu().numpy()\n",
    "force_preds = force_preds.detach().cpu().numpy()\n",
    "energy_true = energy_tensor.numpy()\n",
    "force_true = forces_tensor.numpy()\n",
    "\n",
    "energy_mae = np.mean(np.abs(energy_preds - energy_true))\n",
    "force_mae = np.mean(np.abs(force_preds - force_true))\n",
    "\n",
    "print(\"\\n✅ Prediction complete!\")\n",
    "print(f\"Energy MAE: {energy_mae:.6f}\")\n",
    "print(f\"Force MAE:  {force_mae:.6f}\")\n",
    "\n",
    "# Inspect first sample\n",
    "print(\"\\nFirst sample:\")\n",
    "print(\"Predicted energy:\", energy_preds[0])\n",
    "print(\"True energy:     \", energy_true[0])\n",
    "print(\"Predicted forces:\\n\", force_preds[0])\n",
    "print(\"True forces:\\n\", force_true[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0195b1a-578c-4252-8cf7-aa5466dd1082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e5be0f9-af1a-42db-9497-4e9d8c3ff138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/10000 | Loss: 329.008860\n",
      "Epoch 400/10000 | Loss: 371.334086\n",
      "Epoch 600/10000 | Loss: 405.563853\n",
      "Epoch 800/10000 | Loss: 403.149999\n",
      "Epoch 1000/10000 | Loss: 424.659047\n",
      "Epoch 1200/10000 | Loss: 422.150533\n",
      "Epoch 1400/10000 | Loss: 422.983256\n",
      "Epoch 1600/10000 | Loss: 421.623027\n",
      "Epoch 1800/10000 | Loss: 421.076742\n",
      "Epoch 2000/10000 | Loss: 420.889079\n",
      "Epoch 2200/10000 | Loss: 420.833344\n",
      "Epoch 2400/10000 | Loss: 420.823558\n",
      "Epoch 2600/10000 | Loss: 420.814006\n",
      "Epoch 2800/10000 | Loss: 420.831919\n",
      "Epoch 3000/10000 | Loss: 420.817322\n",
      "Epoch 3200/10000 | Loss: 420.815725\n",
      "Epoch 3400/10000 | Loss: 420.814494\n",
      "Epoch 3600/10000 | Loss: 420.827596\n",
      "Epoch 3800/10000 | Loss: 420.819346\n",
      "Epoch 4000/10000 | Loss: 420.815603\n",
      "Epoch 4200/10000 | Loss: 420.813756\n",
      "Epoch 4400/10000 | Loss: 420.821788\n",
      "Epoch 4600/10000 | Loss: 420.816223\n",
      "Epoch 4800/10000 | Loss: 420.834554\n",
      "Epoch 5000/10000 | Loss: 420.819631\n",
      "Epoch 5200/10000 | Loss: 420.815104\n",
      "Epoch 5400/10000 | Loss: 420.814107\n",
      "Epoch 5600/10000 | Loss: 420.833150\n",
      "Epoch 5800/10000 | Loss: 420.815053\n",
      "Epoch 6000/10000 | Loss: 420.818441\n",
      "Epoch 6200/10000 | Loss: 420.813670\n",
      "Epoch 6400/10000 | Loss: 420.814158\n",
      "Epoch 6600/10000 | Loss: 420.817647\n",
      "Epoch 6800/10000 | Loss: 420.824860\n",
      "Epoch 7000/10000 | Loss: 420.814341\n",
      "Epoch 7200/10000 | Loss: 420.815135\n",
      "Epoch 7400/10000 | Loss: 420.824972\n",
      "Epoch 7600/10000 | Loss: 420.817190\n",
      "Epoch 7800/10000 | Loss: 420.829641\n",
      "Epoch 8000/10000 | Loss: 420.823059\n",
      "Epoch 8200/10000 | Loss: 420.818288\n",
      "Epoch 8400/10000 | Loss: 420.813354\n",
      "Epoch 8600/10000 | Loss: 420.828868\n",
      "Epoch 8800/10000 | Loss: 420.813497\n",
      "Epoch 9000/10000 | Loss: 420.813146\n",
      "Epoch 9200/10000 | Loss: 420.821228\n",
      "Epoch 9400/10000 | Loss: 420.815074\n",
      "Epoch 9600/10000 | Loss: 420.818370\n",
      "Epoch 9800/10000 | Loss: 420.819590\n",
      "Epoch 10000/10000 | Loss: 420.829590\n",
      "\n",
      "✅ Prediction complete!\n",
      "Energy MAE: 0.449402\n",
      "Force MAE:  10.582972\n",
      "\n",
      "First sample:\n",
      "Predicted energy: [-0.973854]\n",
      "True energy:      [-0.9647689]\n",
      "Predicted forces:\n",
      " [[ -0.        -0.       -19.358082]\n",
      " [ -0.        -0.        19.358082]]\n",
      "True forces:\n",
      " [[ 5.2005502e-31 -5.2005502e-31 -1.9374767e+01]\n",
      " [-5.2005502e-31  5.2005502e-31  1.9374767e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load LiH dataset\n",
    "# -------------------------\n",
    "positions = np.load(\"eqnn_force_field_data/Positions.npy\")  # shape (N, num_atoms, 3)\n",
    "forces = np.load(\"eqnn_force_field_data/Forces.npy\")        # shape (N, num_atoms, 3)\n",
    "energy = np.load(\"eqnn_force_field_data/Energy.npy\")        # shape (N,)\n",
    "\n",
    "# -------------------------\n",
    "# 2. Preprocessing\n",
    "# -------------------------\n",
    "energy = energy.reshape(-1, 1)\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "energy_scaled = scaler.fit_transform(energy).flatten()\n",
    "forces_scaled = forces * scaler.scale_[0]\n",
    "positions_centered = positions - positions[:, 0:1, :]  # place first atom at origin\n",
    "\n",
    "# Convert to torch tensors\n",
    "positions_tensor = torch.tensor(positions_centered, dtype=torch.float32)\n",
    "forces_tensor = torch.tensor(forces_scaled, dtype=torch.float32)\n",
    "energy_tensor = torch.tensor(energy_scaled, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Vectorized EQNN Model\n",
    "# -------------------------\n",
    "class EQNN(nn.Module):\n",
    "    def __init__(self, num_atoms=2, hidden_dim=64):\n",
    "        super(EQNN, self).__init__()\n",
    "        self.num_atoms = num_atoms\n",
    "        self.num_pairs = num_atoms * (num_atoms - 1) // 2\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.num_pairs, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, positions):\n",
    "        \"\"\"\n",
    "        positions: (batch, num_atoms, 3)\n",
    "        returns: energy (batch,1), forces (batch,num_atoms,3)\n",
    "        \"\"\"\n",
    "        batch_size = positions.shape[0]\n",
    "\n",
    "        # Vectorized pairwise distances\n",
    "        diff = positions.unsqueeze(2) - positions.unsqueeze(1)  # (batch, N, N, 3)\n",
    "        dists = torch.sqrt(torch.sum(diff**2, dim=-1) + 1e-12)  # (batch, N, N)\n",
    "        \n",
    "        # Take upper triangular without diagonal (i<j)\n",
    "        triu_idx = torch.triu_indices(self.num_atoms, self.num_atoms, offset=1)\n",
    "        dists_pairs = dists[:, triu_idx[0], triu_idx[1]]  # (batch, num_pairs)\n",
    "\n",
    "        # Predict energy\n",
    "        energy = self.mlp(dists_pairs)\n",
    "\n",
    "        # Compute forces\n",
    "        forces = -torch.autograd.grad(\n",
    "            energy.sum(), positions, create_graph=True\n",
    "        )[0]\n",
    "\n",
    "        return energy, forces\n",
    "\n",
    "# -------------------------\n",
    "# 4. Training setup\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "eqnn_model = EQNN(num_atoms=positions_tensor.shape[1], hidden_dim=64).to(device)\n",
    "optimizer = torch.optim.Adam(eqnn_model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs = 10000\n",
    "batch_size = 8\n",
    "N = positions_tensor.shape[0]\n",
    "\n",
    "# -------------------------\n",
    "# 5. Training loop\n",
    "# -------------------------\n",
    "eqnn_model.train()\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(N)\n",
    "    total_loss = 0.0\n",
    "    for i in range(0, N, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        pos_batch = positions_tensor[idx].to(device)\n",
    "        e_batch = energy_tensor[idx].to(device)\n",
    "        f_batch = forces_tensor[idx].to(device)\n",
    "\n",
    "        pos_batch.requires_grad_(True)  # must require grad\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        e_pred, f_pred = eqnn_model(pos_batch)\n",
    "        loss = loss_fn(e_pred, e_batch) + loss_fn(f_pred, f_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/(N//batch_size):.6f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 6. Prediction / Testing\n",
    "# -------------------------\n",
    "eqnn_model.eval()\n",
    "pos_batch = positions_tensor.to(device)\n",
    "pos_batch.requires_grad_(True)\n",
    "energy_preds, force_preds = eqnn_model(pos_batch)\n",
    "energy_preds = energy_preds.detach().cpu().numpy()\n",
    "force_preds = force_preds.detach().cpu().numpy()\n",
    "energy_true = energy_tensor.numpy()\n",
    "force_true = forces_tensor.numpy()\n",
    "\n",
    "energy_mae = np.mean(np.abs(energy_preds - energy_true))\n",
    "force_mae = np.mean(np.abs(force_preds - force_true))\n",
    "\n",
    "print(\"\\n✅ Prediction complete!\")\n",
    "print(f\"Energy MAE: {energy_mae:.6f}\")\n",
    "print(f\"Force MAE:  {force_mae:.6f}\")\n",
    "\n",
    "# Inspect first sample\n",
    "print(\"\\nFirst sample:\")\n",
    "print(\"Predicted energy:\", energy_preds[0])\n",
    "print(\"True energy:     \", energy_true[0])\n",
    "print(\"Predicted forces:\\n\", force_preds[0])\n",
    "print(\"True forces:\\n\", force_true[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10488aed-5034-4b12-adc0-4f7c979fc72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
