{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "058637a2-7187-4c1e-af1c-9239cb074edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter notebook. Call main() directly with parameters:\n",
      "  results = main(n_runs=2, n_epochs=400, output_dir='nh3_results', data_dir='eqnn_force_field_data_nh3_new')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saumya/.conda/envs/penny_skl/lib/python3.12/site-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.8.0 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NH₃ QML Comparison: Four Methods\n",
    "=================================\n",
    "\n",
    "Compares four approaches for predicting NH₃ energy and forces:\n",
    "1. Rotationally Equivariant QML - EQNN-style with SO(3) equivariant encoding\n",
    "2. Non-Equivariant QML - Simple QNN with basic rotations (no symmetry)\n",
    "3. Graph Permutation Equivariant QML - Graph-based encoding with permutation symmetry\n",
    "4. Classical Rotationally Equivariant NN - Classical MLP on pairwise distances (E(3) invariant)\n",
    "\n",
    "Usage (command line):\n",
    "    python run_comparison_nh3.py --n_runs 3 --n_epochs 400 --output_dir results\n",
    "\n",
    "Usage (Jupyter):\n",
    "    from run_comparison_nh3 import main\n",
    "    results = main(n_runs=3, n_epochs=400, output_dir='nh3_comparison_results')\n",
    "\"\"\"\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import numpy as jnp\n",
    "from jax.example_libraries import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def huber(residual, delta=1.0):\n",
    "    \"\"\"Elementwise Huber loss for robust force training.\"\"\"\n",
    "    abs_r = jnp.abs(residual)\n",
    "    quad = 0.5 * residual**2\n",
    "    lin = delta * (abs_r - 0.5 * delta)\n",
    "    return jnp.where(abs_r <= delta, quad, lin)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. ROTATIONALLY EQUIVARIANT QML MODEL (SO(3))\n",
    "# =============================================================================\n",
    "\n",
    "class RotationallyEquivariantQML:\n",
    "    \"\"\"\n",
    "    Rotationally Equivariant QML for NH₃.\n",
    "    Uses singlet initialization, SO(3) equivariant encoding, and Heisenberg-like interactions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, depth=6, rep=2, active_atoms=3, seed=42):\n",
    "        self.depth = depth\n",
    "        self.rep = rep\n",
    "        self.active_atoms = active_atoms  # H1, H2, H3 (N is fixed at origin)\n",
    "        self.n_qubits = active_atoms * rep  # 6 qubits\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=self.n_qubits)\n",
    "        \n",
    "        # Observable for energy measurement\n",
    "        self.observable = (\n",
    "            qml.PauliX(0) @ qml.PauliX(1)\n",
    "            + qml.PauliY(0) @ qml.PauliY(1)\n",
    "            + qml.PauliZ(0) @ qml.PauliZ(1)\n",
    "        )\n",
    "        \n",
    "        self._build_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _singlet(self, wires):\n",
    "        \"\"\"Two-qubit singlet state.\"\"\"\n",
    "        w0, w1 = wires\n",
    "        qml.Hadamard(wires=w0)\n",
    "        qml.PauliZ(wires=w0)\n",
    "        qml.PauliX(wires=w1)\n",
    "        qml.CNOT(wires=[w0, w1])\n",
    "    \n",
    "    def _equivariant_encoding(self, alpha, vec3, wire):\n",
    "        \"\"\"Equivariant encoding of a 3D vector.\"\"\"\n",
    "        r = jnp.array(vec3, dtype=jnp.float64)\n",
    "        norm = jnp.linalg.norm(r) + 1e-12\n",
    "        n = r / norm\n",
    "        theta = alpha * norm\n",
    "        qml.Rot(theta * n[0], theta * n[1], theta * n[2], wires=wire)\n",
    "    \n",
    "    def _pair_layer(self, weight, wires):\n",
    "        \"\"\"Trainable 2-qubit Heisenberg-like interaction.\"\"\"\n",
    "        qml.IsingXX(weight, wires=wires)\n",
    "        qml.IsingYY(weight, wires=wires)\n",
    "        qml.IsingZZ(weight, wires=wires)\n",
    "    \n",
    "    def _build_circuit(self):\n",
    "        \"\"\"Build the quantum circuit as a QNode.\"\"\"\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(coords, params):\n",
    "            \"\"\"\n",
    "            coords: (3, 3) - H1, H2, H3 positions relative to N\n",
    "            params: {\"weights\": (n_qubits, depth), \"alphas\": (n_qubits, depth+1),\n",
    "                     \"head_scale\": scalar, \"head_bias\": scalar}\n",
    "            \"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            alphas = params[\"alphas\"]\n",
    "            \n",
    "            # Initialize singlets on pairs (0,1), (2,3), (4,5)\n",
    "            for i in range(0, self.n_qubits - 1, 2):\n",
    "                self._singlet([i, i + 1])\n",
    "            \n",
    "            # Initial encoding\n",
    "            for i in range(self.n_qubits):\n",
    "                self._equivariant_encoding(alphas[i, 0], coords[i % self.active_atoms], i)\n",
    "            \n",
    "            # D layers of pair interactions + re-encoding\n",
    "            for d in range(self.depth):\n",
    "                qml.Barrier()\n",
    "                \n",
    "                # Even pairings\n",
    "                for i in range(0, self.n_qubits - 1, 2):\n",
    "                    self._pair_layer(weights[i, d], [i, (i + 1) % self.n_qubits])\n",
    "                \n",
    "                # Odd pairings\n",
    "                for i in range(1, self.n_qubits, 2):\n",
    "                    self._pair_layer(weights[i, d], [i, (i + 1) % self.n_qubits])\n",
    "                \n",
    "                # Re-encode geometry\n",
    "                for i in range(self.n_qubits):\n",
    "                    self._equivariant_encoding(alphas[i, d + 1], coords[i % self.active_atoms], i)\n",
    "            \n",
    "            return qml.expval(self.observable)\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, in_axes=(0, None), out_axes=0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        weights0 = np.zeros((self.n_qubits, self.depth), dtype=np.float64)\n",
    "        weights0[0] = np.random.uniform(0.0, np.pi, size=(self.depth,))\n",
    "        \n",
    "        self.params = {\n",
    "            \"weights\": jnp.array(weights0),\n",
    "            \"alphas\": jnp.ones((self.n_qubits, self.depth + 1), dtype=jnp.float64),\n",
    "            \"head_scale\": jnp.array(1.0, dtype=jnp.float64),\n",
    "            \"head_bias\": jnp.array(0.0, dtype=jnp.float64),\n",
    "        }\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def predict_energy(self, coords, params):\n",
    "        \"\"\"Predict energy with linear head.\"\"\"\n",
    "        raw_E = self.vec_circuit(coords, params)\n",
    "        return params[\"head_scale\"] * raw_E + params[\"head_bias\"]\n",
    "    \n",
    "    def predict_forces(self, coords, params):\n",
    "        \"\"\"Predict forces as negative gradient of energy.\"\"\"\n",
    "        grad_fn = jax.grad(lambda c, p: self.circuit(c, p), argnums=0)\n",
    "        vec_grad = jax.vmap(grad_fn, in_axes=(0, None), out_axes=0)\n",
    "        raw_F = -vec_grad(coords, params)\n",
    "        return params[\"head_scale\"] * raw_F\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. NON-EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class NonEquivariantQML:\n",
    "    \"\"\"\n",
    "    Simple non-equivariant QNN for NH₃.\n",
    "    Uses basic rotations without symmetry preservation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=6, depth=4, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the simple QNN circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            \"\"\"\n",
    "            positions: (4, 3) - [N, H1, H2, H3] coordinates\n",
    "            params: {\"weights\": (depth, num_qubits, 3)}\n",
    "            \"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            \n",
    "            # Compute simple geometric features (not respecting symmetry)\n",
    "            # Bond lengths\n",
    "            d1 = jnp.linalg.norm(positions[1] - positions[0])\n",
    "            d2 = jnp.linalg.norm(positions[2] - positions[0])\n",
    "            d3 = jnp.linalg.norm(positions[3] - positions[0])\n",
    "            \n",
    "            # Average bond length\n",
    "            avg_dist = (d1 + d2 + d3) / 3.0\n",
    "            \n",
    "            # Initialize\n",
    "            for i in range(num_qubits):\n",
    "                qml.RY(0.5, wires=i)\n",
    "            \n",
    "            # Simple layers\n",
    "            for layer in range(depth):\n",
    "                # Encode distances directly (breaks permutation symmetry)\n",
    "                qml.RY(weights[layer, 0, 0] * d1, wires=0)\n",
    "                qml.RY(weights[layer, 1, 0] * d2, wires=1)\n",
    "                qml.RY(weights[layer, 2, 0] * d3, wires=2)\n",
    "                qml.RY(weights[layer, 3, 0] * avg_dist, wires=3)\n",
    "                qml.RY(weights[layer, 4, 0] * d1, wires=4)\n",
    "                qml.RY(weights[layer, 5, 0] * d2, wires=5)\n",
    "                \n",
    "                # Entangle\n",
    "                for i in range(num_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "                \n",
    "                # More rotations\n",
    "                for i in range(num_qubits):\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "                    qml.RY(weights[layer, i, 2], wires=i)\n",
    "            \n",
    "            return qml.expval(sum(qml.PauliZ(i) for i in range(num_qubits)))\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        weights = np.random.normal(0, 0.1, (self.depth, self.num_qubits, 3))\n",
    "        self.params = {\"weights\": jnp.array(weights)}\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. GRAPH PERMUTATION EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class GraphPermutationEquivariantQML:\n",
    "    \"\"\"\n",
    "    Graph Permutation Equivariant QML for NH₃.\n",
    "    Encodes N-H bonds as graph edges with geometric features.\n",
    "    Uses permutation-symmetric encoding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits=6, depth=4, seed=42):\n",
    "        self.n_qubits = n_qubits  # 3 bonds × 2 qubits per bond\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        self._build_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _build_circuit(self):\n",
    "        \"\"\"Build the graph-based quantum circuit.\"\"\"\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            \"\"\"\n",
    "            positions: (4, 3) - [N, H1, H2, H3] coordinates\n",
    "            params: {\"weights\": (depth, n_qubits, 3)}\n",
    "            \"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            \n",
    "            # N at index 0, H atoms at indices 1, 2, 3\n",
    "            N_pos = positions[0]\n",
    "            H_positions = positions[1:]  # (3, 3)\n",
    "            \n",
    "            # Compute bond vectors and distances\n",
    "            bonds = H_positions - N_pos[None, :]  # (3, 3)\n",
    "            distances = jnp.linalg.norm(bonds, axis=1)  # (3,)\n",
    "            \n",
    "            # Compute angles between bonds\n",
    "            def compute_angle(v1, v2):\n",
    "                cos_angle = jnp.dot(v1, v2) / (jnp.linalg.norm(v1) * jnp.linalg.norm(v2) + 1e-12)\n",
    "                return jnp.arccos(jnp.clip(cos_angle, -1.0, 1.0))\n",
    "            \n",
    "            angle_01 = compute_angle(bonds[0], bonds[1])\n",
    "            angle_02 = compute_angle(bonds[0], bonds[2])\n",
    "            angle_12 = compute_angle(bonds[1], bonds[2])\n",
    "            \n",
    "            # Initialize qubits\n",
    "            for i in range(self.n_qubits):\n",
    "                qml.RY(0.5, wires=i)\n",
    "            \n",
    "            # Apply layers\n",
    "            for layer in range(self.depth):\n",
    "                # Encode bond distances (symmetric across bond pairs)\n",
    "                qml.RY(weights[layer, 0, 0] * distances[0], wires=0)\n",
    "                qml.RY(weights[layer, 1, 0] * distances[0], wires=1)\n",
    "                qml.RY(weights[layer, 2, 0] * distances[1], wires=2)\n",
    "                qml.RY(weights[layer, 3, 0] * distances[1], wires=3)\n",
    "                qml.RY(weights[layer, 4, 0] * distances[2], wires=4)\n",
    "                qml.RY(weights[layer, 5, 0] * distances[2], wires=5)\n",
    "                \n",
    "                # Entangle within bonds\n",
    "                qml.CNOT(wires=[0, 1])\n",
    "                qml.CNOT(wires=[2, 3])\n",
    "                qml.CNOT(wires=[4, 5])\n",
    "                \n",
    "                # Encode angular information\n",
    "                qml.RZ(weights[layer, 0, 1] * angle_01, wires=0)\n",
    "                qml.RZ(weights[layer, 2, 1] * angle_01, wires=2)\n",
    "                qml.RZ(weights[layer, 0, 2] * angle_02, wires=0)\n",
    "                qml.RZ(weights[layer, 4, 2] * angle_02, wires=4)\n",
    "                qml.RZ(weights[layer, 2, 2] * angle_12, wires=2)\n",
    "                qml.RZ(weights[layer, 4, 2] * angle_12, wires=4)\n",
    "                \n",
    "                # Cross-bond entanglement\n",
    "                qml.CNOT(wires=[1, 2])\n",
    "                qml.CNOT(wires=[3, 4])\n",
    "                qml.CNOT(wires=[5, 0])\n",
    "                \n",
    "                # Additional rotations\n",
    "                for i in range(self.n_qubits):\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "                    qml.RY(weights[layer, i, 2], wires=i)\n",
    "            \n",
    "            return qml.expval(qml.sum(*(qml.PauliZ(i) for i in range(self.n_qubits))))\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, in_axes=(0, None), out_axes=0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        self.params = {\n",
    "            \"weights\": jnp.array(np.random.normal(0, 0.1, (self.depth, self.n_qubits, 3)))\n",
    "        }\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. CLASSICAL ROTATIONALLY EQUIVARIANT NN (E(3) INVARIANT)\n",
    "# =============================================================================\n",
    "\n",
    "class ClassicalRotationallyEquivariantNN:\n",
    "    \"\"\"\n",
    "    Improved Classical Rotationally Equivariant Neural Network for NH₃.\n",
    "    \n",
    "    Key improvements over basic MLP:\n",
    "    1. Expanded features: distances, inverse distances, angles, Morse-like terms\n",
    "    2. SiLU activation (smooth, better gradients for force autodiff)\n",
    "    3. Feature normalization for stable training\n",
    "    4. Larger network with skip connections\n",
    "    5. Radial basis function encoding for physics inductive bias\n",
    "    \n",
    "    Uses E(3) invariant features (distances, angles).\n",
    "    Energy predicted from invariants, forces via autodiff.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dims=[128, 128, 64], seed=42):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.seed = seed\n",
    "        self._init_params()\n",
    "        self._create_model()\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters with He initialization.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        # Expanded feature set:\n",
    "        # 6 distances + 6 inverse distances + 6 Morse-like + 3 angles + 3 cos(angles) = 24 features\n",
    "        n_features = 24\n",
    "        \n",
    "        # Main MLP\n",
    "        layer_sizes = [n_features] + self.hidden_dims + [1]\n",
    "        \n",
    "        params = {\n",
    "            \"weights\": [],\n",
    "            \"biases\": [],\n",
    "            \"skip_weights\": [],  # For skip connections\n",
    "            \"output_scale\": jnp.array(1.0),\n",
    "            \"output_bias\": jnp.array(0.0),\n",
    "        }\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            fan_in = layer_sizes[i]\n",
    "            fan_out = layer_sizes[i + 1]\n",
    "            \n",
    "            # He initialization for SiLU\n",
    "            std = np.sqrt(2.0 / fan_in)\n",
    "            W = np.random.normal(0, std, (fan_in, fan_out))\n",
    "            b = np.zeros(fan_out)\n",
    "            \n",
    "            params[\"weights\"].append(jnp.array(W))\n",
    "            params[\"biases\"].append(jnp.array(b))\n",
    "        \n",
    "        # Skip connection from input to final hidden layer\n",
    "        skip_std = np.sqrt(2.0 / n_features)\n",
    "        params[\"skip_weights\"] = jnp.array(np.random.normal(0, skip_std, (n_features, self.hidden_dims[-1])))\n",
    "        \n",
    "        # Radial basis function parameters for pairwise terms\n",
    "        # 6 distance pairs x 8 RBF centers\n",
    "        params[\"rbf_coeffs\"] = jnp.array(np.random.normal(0, 0.1, (6, 8)))\n",
    "        params[\"rbf_output\"] = jnp.array(np.random.normal(0, 0.1, (6,)))\n",
    "        \n",
    "        self.params = params\n",
    "    \n",
    "    def _create_model(self):\n",
    "        \"\"\"Create the forward pass function with improved architecture.\"\"\"\n",
    "        \n",
    "        def silu(x):\n",
    "            \"\"\"SiLU/Swish activation - smooth, better for gradients.\"\"\"\n",
    "            return x * jax.nn.sigmoid(x)\n",
    "        \n",
    "        def compute_features(positions):\n",
    "            \"\"\"\n",
    "            Compute E(3) invariant features from positions.\n",
    "            positions: (4, 3) - [N, H1, H2, H3]\n",
    "            \n",
    "            Returns: (features, distances)\n",
    "            \"\"\"\n",
    "            # Compute all 6 pairwise distances with numerical stability\n",
    "            eps = 1e-8\n",
    "            d_NH1 = jnp.linalg.norm(positions[1] - positions[0]) + eps\n",
    "            d_NH2 = jnp.linalg.norm(positions[2] - positions[0]) + eps\n",
    "            d_NH3 = jnp.linalg.norm(positions[3] - positions[0]) + eps\n",
    "            d_H1H2 = jnp.linalg.norm(positions[2] - positions[1]) + eps\n",
    "            d_H1H3 = jnp.linalg.norm(positions[3] - positions[1]) + eps\n",
    "            d_H2H3 = jnp.linalg.norm(positions[3] - positions[2]) + eps\n",
    "            \n",
    "            distances = jnp.array([d_NH1, d_NH2, d_NH3, d_H1H2, d_H1H3, d_H2H3])\n",
    "            \n",
    "            # Normalized distances (typical N-H ~ 1.0 Å, H-H ~ 1.6 Å)\n",
    "            dist_norm = distances / 1.5  # Scale to ~1\n",
    "            \n",
    "            # Inverse distances (Coulomb-like)\n",
    "            inv_dist = 1.0 / distances\n",
    "            inv_dist_norm = inv_dist / 1.0  # Scale appropriately\n",
    "            \n",
    "            # Morse-like features: exp(-alpha * (r - r_eq))\n",
    "            # This captures the shape of bond potentials\n",
    "            r_eq = jnp.array([1.01, 1.01, 1.01, 1.63, 1.63, 1.63])  # Approx equilibrium\n",
    "            alpha = 2.0\n",
    "            morse = jnp.exp(-alpha * (distances - r_eq))\n",
    "            \n",
    "            # Compute H-N-H angles using dot products (more stable than law of cosines)\n",
    "            def compute_angle(p1, p2, p_center):\n",
    "                \"\"\"Angle at p_center between p1-p_center-p2.\"\"\"\n",
    "                v1 = p1 - p_center\n",
    "                v2 = p2 - p_center\n",
    "                cos_angle = jnp.dot(v1, v2) / (jnp.linalg.norm(v1) * jnp.linalg.norm(v2) + eps)\n",
    "                return jnp.arccos(jnp.clip(cos_angle, -1.0 + eps, 1.0 - eps))\n",
    "            \n",
    "            # H-N-H angles (at N atom)\n",
    "            angle_H1NH2 = compute_angle(positions[1], positions[2], positions[0])\n",
    "            angle_H1NH3 = compute_angle(positions[1], positions[3], positions[0])\n",
    "            angle_H2NH3 = compute_angle(positions[2], positions[3], positions[0])\n",
    "            \n",
    "            angles = jnp.array([angle_H1NH2, angle_H1NH3, angle_H2NH3])\n",
    "            angles_norm = angles / jnp.pi  # Normalize to [0, 1]\n",
    "            \n",
    "            # Cosine of angles (often more useful than raw angles)\n",
    "            cos_angles = jnp.cos(angles)\n",
    "            \n",
    "            # Concatenate all features\n",
    "            features = jnp.concatenate([\n",
    "                dist_norm,      # 6: normalized distances\n",
    "                inv_dist_norm,  # 6: inverse distances\n",
    "                morse,          # 6: Morse-like features\n",
    "                angles_norm,    # 3: normalized angles\n",
    "                cos_angles,     # 3: cosine of angles\n",
    "            ])\n",
    "            \n",
    "            return features, distances\n",
    "        \n",
    "        def rbf_energy(distances, params):\n",
    "            \"\"\"\n",
    "            Radial basis function energy contribution.\n",
    "            Provides physics-based inductive bias for pairwise interactions.\n",
    "            \"\"\"\n",
    "            # RBF centers (typical bond lengths in Angstrom)\n",
    "            centers = jnp.linspace(0.8, 2.5, 8)\n",
    "            width = 0.2\n",
    "            \n",
    "            # Compute RBF features for each distance\n",
    "            # Shape: (6 distances, 8 centers)\n",
    "            rbf = jnp.exp(-((distances[:, None] - centers[None, :]) ** 2) / (2 * width ** 2))\n",
    "            \n",
    "            # Weighted sum per distance pair\n",
    "            pair_energies = jnp.sum(rbf * params[\"rbf_coeffs\"], axis=1)  # (6,)\n",
    "            \n",
    "            # Total RBF contribution\n",
    "            return jnp.dot(pair_energies, params[\"rbf_output\"])\n",
    "        \n",
    "        def mlp_forward(features, params):\n",
    "            \"\"\"MLP with skip connections and SiLU activation.\"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            biases = params[\"biases\"]\n",
    "            \n",
    "            h = features\n",
    "            \n",
    "            for i in range(len(weights) - 1):\n",
    "                h = jnp.dot(h, weights[i]) + biases[i]\n",
    "                h = silu(h)\n",
    "                \n",
    "                # Add skip connection to last hidden layer\n",
    "                if i == len(weights) - 2:\n",
    "                    skip = jnp.dot(features, params[\"skip_weights\"])\n",
    "                    h = h + 0.1 * skip  # Scaled skip connection\n",
    "            \n",
    "            # Output layer\n",
    "            h = jnp.dot(h, weights[-1]) + biases[-1]\n",
    "            return h.squeeze(-1)\n",
    "        \n",
    "        def energy_from_positions(positions, params):\n",
    "            \"\"\"\n",
    "            Compute energy from atomic positions.\n",
    "            Combines MLP prediction with RBF pairwise terms.\n",
    "            \"\"\"\n",
    "            # Compute features\n",
    "            features, distances = compute_features(positions)\n",
    "            \n",
    "            # MLP energy\n",
    "            mlp_energy = mlp_forward(features, params)\n",
    "            \n",
    "            # RBF pairwise energy (physics bias)\n",
    "            rbf_contrib = rbf_energy(distances, params)\n",
    "            \n",
    "            # Combined with learnable scaling\n",
    "            total_energy = params[\"output_scale\"] * mlp_energy + rbf_contrib + params[\"output_bias\"]\n",
    "            \n",
    "            return total_energy\n",
    "        \n",
    "        def force_from_positions(positions, params):\n",
    "            \"\"\"Compute forces as negative gradient of energy.\"\"\"\n",
    "            grad_fn = jax.grad(energy_from_positions, argnums=0)\n",
    "            return -grad_fn(positions, params)\n",
    "        \n",
    "        self.energy_fn = energy_from_positions\n",
    "        self.force_fn = force_from_positions\n",
    "        self.vec_energy = jax.vmap(energy_from_positions, (0, None), 0)\n",
    "        self.vec_force = jax.vmap(force_from_positions, (0, None), 0)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def train_rotationally_equivariant(model, pos_H, E_train, F_train, n_epochs=400, lr=3e-3, \n",
    "                                    wE=1.0, wF_max=5.0, warmup_frac=0.4):\n",
    "    \"\"\"\n",
    "    Train rotationally equivariant QML model with force warmup curriculum.\n",
    "    \"\"\"\n",
    "    params = model.get_params()\n",
    "    \n",
    "    # Force RMS for normalization\n",
    "    F_rms = jnp.sqrt(jnp.mean(F_train**2)) + 1e-12\n",
    "    F_train_norm = F_train / F_rms\n",
    "    \n",
    "    # Gradient function for forces\n",
    "    grad_energy_single = jax.grad(lambda c, p: model.circuit(c, p), argnums=0)\n",
    "    vec_grad = jax.vmap(grad_energy_single, in_axes=(0, None), out_axes=0)\n",
    "    \n",
    "    def loss_fn(params, coords, E_target, F_target_norm, wF):\n",
    "        raw_E = model.vec_circuit(coords, params)\n",
    "        raw_F = -vec_grad(coords, params)\n",
    "        \n",
    "        scale = params[\"head_scale\"]\n",
    "        bias = params[\"head_bias\"]\n",
    "        \n",
    "        E_pred = scale * raw_E + bias\n",
    "        F_pred_scaled = scale * raw_F\n",
    "        F_pred_norm = F_pred_scaled / F_rms\n",
    "        \n",
    "        lE = jnp.mean((E_pred - E_target)**2)\n",
    "        resid_F = F_pred_norm - F_target_norm\n",
    "        lF = jnp.mean(huber(resid_F, delta=1.0))\n",
    "        \n",
    "        return wE * lE + wF * lF, (lE, lF)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(params)\n",
    "    \n",
    "    warmup_steps = int(warmup_frac * n_epochs)\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for step in range(n_epochs):\n",
    "        wF = wF_max * min(step / warmup_steps, 1.0) if warmup_steps > 0 else wF_max\n",
    "        \n",
    "        params = get_params(opt_state)\n",
    "        \n",
    "        def wrapped(p):\n",
    "            total, comps = loss_fn(p, pos_H, E_train, F_train_norm, wF)\n",
    "            return total, comps\n",
    "        \n",
    "        (loss_val, (lE, lF)), grads = jax.value_and_grad(wrapped, has_aux=True)(params)\n",
    "        opt_state = opt_update(step, grads, opt_state)\n",
    "        \n",
    "        if (step + 1) % max(1, n_epochs // 20) == 0:\n",
    "            history[\"epoch\"].append(step + 1)\n",
    "            history[\"train_loss\"].append(float(loss_val))\n",
    "            history[\"test_E_loss\"].append(float(lE))\n",
    "            history[\"test_F_loss\"].append(float(lF))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_non_equivariant(model, positions, E_train, F_train, n_epochs=400, lr=0.01,\n",
    "                          lambda_E=2.0, lambda_F=1.0):\n",
    "    \"\"\"Train the non-equivariant QML model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_H = F_pred_full[:, 1:, :]  # H atoms only\n",
    "        F_loss = jnp.mean((F_pred_H - F_target) ** 2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), positions, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_graph_permutation_equivariant(model, positions, E_train, F_train, \n",
    "                                         n_epochs_energy=200, n_epochs_combined=200, \n",
    "                                         lr=0.01):\n",
    "    \"\"\"\n",
    "    Train graph permutation equivariant QML with two-phase training.\n",
    "    \"\"\"\n",
    "    # Phase 1: Energy only\n",
    "    @jax.jit\n",
    "    def energy_loss(params, positions, E_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        return jnp.mean((E_pred - E_target)**2)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for step in range(n_epochs_energy):\n",
    "        params = get_params(opt_state)\n",
    "        loss, grads = jax.value_and_grad(energy_loss)(params, positions, E_train)\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads)))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm), grads)\n",
    "        \n",
    "        opt_state = opt_update(step, grads, opt_state)\n",
    "    \n",
    "    # Phase 2: Combined\n",
    "    trained_params = get_params(opt_state)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(lambda c, p: model.circuit(c, p), argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, in_axes=(0, None), out_axes=0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target)**2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_H = F_pred_full[:, 1:, :]\n",
    "        F_loss = jnp.mean((F_pred_H - F_target)**2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        return 2.0 * E_loss + 1.0 * F_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_state = opt_init(trained_params)\n",
    "    \n",
    "    for step in range(n_epochs_combined):\n",
    "        params = get_params(opt_state)\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            params, positions, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads)))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm), grads)\n",
    "        \n",
    "        opt_state = opt_update(step, grads, opt_state)\n",
    "        \n",
    "        if (step + 1) % max(1, n_epochs_combined // 20) == 0:\n",
    "            history[\"epoch\"].append(n_epochs_energy + step + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_classical_equivariant(model, positions, E_train, F_train, n_epochs=400, \n",
    "                                 lr=0.003, lambda_E=1.0, lambda_F=2.0, warmup_frac=0.3):\n",
    "    \"\"\"\n",
    "    Train the classical rotationally equivariant NN with improved strategy.\n",
    "    \n",
    "    Uses two-phase training:\n",
    "    1. Energy-only warmup phase\n",
    "    2. Combined energy + force training with gradual force weight increase\n",
    "    \"\"\"\n",
    "    warmup_epochs = int(n_epochs * warmup_frac)\n",
    "    \n",
    "    # Phase 1: Energy-only loss\n",
    "    @jax.jit\n",
    "    def energy_loss(params, positions, E_target):\n",
    "        E_pred = model.vec_energy(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        return jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "    \n",
    "    # Phase 2: Combined loss with Huber for forces\n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target, wF):\n",
    "        E_pred = model.vec_energy(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = model.vec_force(positions, params)\n",
    "        F_pred_H = F_pred_full[:, 1:, :]  # H atoms only\n",
    "        \n",
    "        # Huber loss for forces (more robust to outliers)\n",
    "        F_residual = F_pred_H - F_target\n",
    "        F_loss = jnp.mean(huber(F_residual, delta=0.5))\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + wF * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    # Use Adam with slightly higher learning rate\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    # Phase 1: Energy warmup\n",
    "    for epoch in range(warmup_epochs):\n",
    "        loss, grads = jax.value_and_grad(energy_loss)(\n",
    "            get_params(opt_state), positions, E_train\n",
    "        )\n",
    "        \n",
    "        # Gradient clipping\n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 5.0:\n",
    "            grads = jax.tree.map(lambda g: g * (5.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            # Compute force loss for logging\n",
    "            F_pred_full = model.vec_force(positions, get_params(opt_state))\n",
    "            F_pred_H = F_pred_full[:, 1:, :]\n",
    "            F_loss = float(jnp.mean((F_pred_H - F_train) ** 2))\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(loss))\n",
    "            history[\"test_F_loss\"].append(F_loss)\n",
    "    \n",
    "    # Phase 2: Combined training with force weight ramp\n",
    "    for epoch in range(warmup_epochs, n_epochs):\n",
    "        # Gradually increase force weight\n",
    "        progress = (epoch - warmup_epochs) / max(1, n_epochs - warmup_epochs)\n",
    "        wF = lambda_F * min(1.0, progress * 2)  # Ramp up over first half of phase 2\n",
    "        \n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), positions, E_train, F_train, wF\n",
    "        )\n",
    "        \n",
    "        # Gradient clipping\n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 5.0:\n",
    "            grads = jax.tree.map(lambda g: g * (5.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(E_pred, F_pred, E_true, F_true, indices_test, \n",
    "                   energy_scaler, force_scaler, indices_train, \n",
    "                   E_pred_train=None, F_pred_train=None, E_train_true=None, F_train_true=None):\n",
    "    \"\"\"\n",
    "    Evaluate model with post-correction and compute metrics.\n",
    "    \"\"\"\n",
    "    # Post-correction for energy (quadratic)\n",
    "    def corr_E(E, a, b, c):\n",
    "        return a * E**2 + b * E + c\n",
    "    \n",
    "    try:\n",
    "        if E_pred_train is not None and E_train_true is not None:\n",
    "            popt_E, _ = curve_fit(corr_E, E_pred_train, E_train_true)\n",
    "            E_pred_corr = corr_E(E_pred, *popt_E)\n",
    "        else:\n",
    "            E_pred_corr = E_pred\n",
    "    except:\n",
    "        E_pred_corr = E_pred\n",
    "    \n",
    "    # Post-correction for forces (linear)\n",
    "    try:\n",
    "        if F_pred_train is not None and F_train_true is not None:\n",
    "            F_pred_flat = F_pred_train.flatten().reshape(-1, 1)\n",
    "            F_true_flat = F_train_true.flatten().reshape(-1, 1)\n",
    "            lr_model = LinearRegression()\n",
    "            lr_model.fit(F_pred_flat, F_true_flat)\n",
    "            F_pred_corr = lr_model.predict(F_pred.flatten().reshape(-1, 1)).reshape(F_pred.shape)\n",
    "        else:\n",
    "            F_pred_corr = F_pred\n",
    "    except:\n",
    "        F_pred_corr = F_pred\n",
    "    \n",
    "    # Inverse transform to original units\n",
    "    E_pred_final = energy_scaler.inverse_transform(E_pred_corr.reshape(-1, 1)).flatten()\n",
    "    E_true_orig = energy_scaler.inverse_transform(E_true.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    F_pred_final = force_scaler.inverse_transform(F_pred_corr.flatten().reshape(-1, 1)).reshape(F_pred_corr.shape)\n",
    "    F_true_orig = force_scaler.inverse_transform(F_true.flatten().reshape(-1, 1)).reshape(F_true.shape)\n",
    "    \n",
    "    # Compute metrics on test set\n",
    "    E_test_pred = E_pred_final[indices_test]\n",
    "    E_test_true = E_true_orig[indices_test]\n",
    "    \n",
    "    E_mae = np.mean(np.abs(E_test_pred - E_test_true))\n",
    "    E_rmse = np.sqrt(np.mean((E_test_pred - E_test_true)**2))\n",
    "    E_r2 = 1 - np.sum((E_test_pred - E_test_true)**2) / np.sum((E_test_true - E_test_true.mean())**2)\n",
    "    \n",
    "    F_test_pred = F_pred_final[indices_test].flatten()\n",
    "    F_test_true = F_true_orig[indices_test].flatten()\n",
    "    \n",
    "    F_mae = np.mean(np.abs(F_test_pred - F_test_true))\n",
    "    F_rmse = np.sqrt(np.mean((F_test_pred - F_test_true)**2))\n",
    "    F_r2 = 1 - np.sum((F_test_pred - F_test_true)**2) / np.sum((F_test_true - F_test_true.mean())**2)\n",
    "    \n",
    "    return {\n",
    "        \"E_mae_Ha\": float(E_mae),\n",
    "        \"E_mae_eV\": float(E_mae * 27.2114),\n",
    "        \"E_rmse_Ha\": float(E_rmse),\n",
    "        \"E_rmse_eV\": float(E_rmse * 27.2114),\n",
    "        \"E_r2\": float(E_r2),\n",
    "        \"F_mae\": float(F_mae),\n",
    "        \"F_rmse\": float(F_rmse),\n",
    "        \"F_r2\": float(F_r2),\n",
    "    }, {\n",
    "        \"E_pred\": E_pred_final[indices_test].tolist(),\n",
    "        \"E_true\": E_test_true.tolist(),\n",
    "        \"F_pred\": F_pred_final[indices_test].tolist(),\n",
    "        \"F_true\": F_true_orig[indices_test].tolist(),\n",
    "        \"indices_test\": indices_test.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTTING\n",
    "# =============================================================================\n",
    "\n",
    "def create_comparison_plots(all_results, output_dir):\n",
    "    \"\"\"Create comparison plots for all four methods.\"\"\"\n",
    "    \n",
    "    methods = [\"rotationally_equivariant\", \"non_equivariant\", \"graph_permutation_equivariant\", \"classical_equivariant\"]\n",
    "    method_names = [\"Rot. Equiv. QML\", \"Non-Equiv. QML\", \"Graph Perm. QML\", \"Classical Equiv. NN\"]\n",
    "    colors = [\"#2ecc71\", \"#e74c3c\", \"#3498db\", \"#9b59b6\"]\n",
    "    \n",
    "    # Figure 1: Training curves (2x2)\n",
    "    fig1, axes1 = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes1 = axes1.flatten()\n",
    "    \n",
    "    for idx, (method, name, color) in enumerate(zip(methods, method_names, colors)):\n",
    "        ax = axes1[idx]\n",
    "        \n",
    "        if len(all_results[method][\"runs\"]) > 0:\n",
    "            history = all_results[method][\"runs\"][0][\"history\"]\n",
    "            if history.get(\"epoch\"):\n",
    "                epochs = history[\"epoch\"]\n",
    "                ax.plot(epochs, history[\"train_loss\"], '-', color=color, lw=2, label='Train Loss')\n",
    "                if history.get(\"test_E_loss\"):\n",
    "                    ax.plot(epochs, history[\"test_E_loss\"], '--', color=color, lw=2, alpha=0.7, label='E Loss')\n",
    "                if history.get(\"test_F_loss\"):\n",
    "                    ax.plot(epochs, history[\"test_F_loss\"], ':', color=color, lw=2, alpha=0.7, label='F Loss')\n",
    "                \n",
    "                ax.set_xlabel('Epoch')\n",
    "                ax.set_ylabel('Loss')\n",
    "                ax.set_title(f'{name}\\nTraining Curves')\n",
    "                ax.legend(fontsize=8)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Figure 2: Bar chart comparisons\n",
    "    fig2, axes2 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    x_pos = np.arange(len(methods))\n",
    "    \n",
    "    # Energy R² comparison\n",
    "    ax = axes2[0]\n",
    "    E_r2_means = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"mean\"] for m in methods]\n",
    "    E_r2_stds = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(x_pos, E_r2_means, yerr=E_r2_stds, color=colors, alpha=0.8, capsize=5)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('Energy R²')\n",
    "    ax.set_title('Energy Prediction R²')\n",
    "    ax.set_ylim([0, 1.15])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, E_r2_means):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{mean:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Force R² comparison\n",
    "    ax = axes2[1]\n",
    "    F_r2_means = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"mean\"] for m in methods]\n",
    "    F_r2_stds = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(x_pos, F_r2_means, yerr=F_r2_stds, color=colors, alpha=0.8, capsize=5)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('Force R²')\n",
    "    ax.set_title('Force Prediction R²')\n",
    "    ax.set_ylim([0, 1.15])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, F_r2_means):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{mean:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # MAE comparison\n",
    "    ax = axes2[2]\n",
    "    width = 0.35\n",
    "    E_mae_means = [all_results[m][\"metrics_summary\"][\"E_mae_Ha\"][\"mean\"] * 1000 for m in methods]\n",
    "    F_mae_means = [all_results[m][\"metrics_summary\"][\"F_mae\"][\"mean\"] for m in methods]\n",
    "    \n",
    "    bars1 = ax.bar(x_pos - width/2, E_mae_means, width, color=colors, alpha=0.6, label='Energy MAE (mHa)')\n",
    "    bars2 = ax.bar(x_pos + width/2, F_mae_means, width, color=colors, alpha=1.0, hatch='//', label='Force MAE (eV/Å)')\n",
    "    \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title('Mean Absolute Errors')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'metrics_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Figure 3: Scatter plots (2x4)\n",
    "    fig3, axes3 = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    for idx, (method, name, color) in enumerate(zip(methods, method_names, colors)):\n",
    "        if len(all_results[method][\"runs\"]) > 0:\n",
    "            predictions = all_results[method][\"runs\"][0][\"predictions\"]\n",
    "            \n",
    "            E_pred = np.array(predictions[\"E_pred\"])\n",
    "            E_true = np.array(predictions[\"E_true\"])\n",
    "            F_pred = np.array(predictions[\"F_pred\"]).flatten()\n",
    "            F_true = np.array(predictions[\"F_true\"]).flatten()\n",
    "            \n",
    "            metrics = all_results[method][\"runs\"][0][\"metrics\"]\n",
    "            \n",
    "            # Energy scatter\n",
    "            ax = axes3[0, idx]\n",
    "            ax.scatter(E_true, E_pred, c=color, alpha=0.6, s=20)\n",
    "            lims = [min(E_true.min(), E_pred.min()), max(E_true.max(), E_pred.max())]\n",
    "            ax.plot(lims, lims, 'k--', lw=2)\n",
    "            ax.set_xlabel('True Energy (Ha)')\n",
    "            ax.set_ylabel('Predicted Energy (Ha)')\n",
    "            ax.set_title(f'{name}\\nE R²={metrics[\"E_r2\"]:.3f}')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Force scatter\n",
    "            ax = axes3[1, idx]\n",
    "            ax.scatter(F_true, F_pred, c=color, alpha=0.6, s=20)\n",
    "            lims = [min(F_true.min(), F_pred.min()), max(F_true.max(), F_pred.max())]\n",
    "            ax.plot(lims, lims, 'k--', lw=2)\n",
    "            ax.set_xlabel('True Force (eV/Å)')\n",
    "            ax.set_ylabel('Predicted Force (eV/Å)')\n",
    "            ax.set_title(f'{name}\\nF R²={metrics[\"F_r2\"]:.3f}')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'predictions_scatter.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Figure 4: Summary comparison\n",
    "    fig4, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    width = 0.35\n",
    "    x = np.arange(len(methods))\n",
    "    \n",
    "    E_r2 = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"mean\"] for m in methods]\n",
    "    F_r2 = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"mean\"] for m in methods]\n",
    "    E_r2_err = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"std\"] for m in methods]\n",
    "    F_r2_err = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, E_r2, width, yerr=E_r2_err, label='Energy R²', \n",
    "                   color='steelblue', alpha=0.8, capsize=4)\n",
    "    bars2 = ax.bar(x + width/2, F_r2, width, yerr=F_r2_err, label='Force R²', \n",
    "                   color='coral', alpha=0.8, capsize=4)\n",
    "    \n",
    "    ax.set_ylabel('R² Score')\n",
    "    ax.set_title('NH₃ Method Comparison: Energy vs Force Prediction Performance')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(method_names, fontsize=10)\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'summary_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Plots saved to: {output_dir}/\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "def run_comparison(n_runs=2, n_epochs=400, output_dir=\"nh3_comparison_results\", \n",
    "                   data_dir=\"eqnn_force_field_data_nh3_new\"):\n",
    "    \"\"\"\n",
    "    Run comparison between all four methods on NH₃ data.\n",
    "    \"\"\"\n",
    "    print(\"=\"*90)\n",
    "    print(\"NH₃ Energy/Force Prediction: Four Methods Comparison\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"Methods:\")\n",
    "    print(\"  1. Rotationally Equivariant QML (SO(3) symmetry)\")\n",
    "    print(\"  2. Non-Equivariant QML (baseline)\")\n",
    "    print(\"  3. Graph Permutation Equivariant QML (permutation symmetry)\")\n",
    "    print(\"  4. Classical Rotationally Equivariant NN (E(3) invariant MLP)\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    try:\n",
    "        energy = np.load(os.path.join(data_dir, \"Energy.npy\"))\n",
    "        forces = np.load(os.path.join(data_dir, \"Forces.npy\"))\n",
    "        positions = np.load(os.path.join(data_dir, \"Positions.npy\"))\n",
    "        print(f\"  Loaded {len(energy)} samples\")\n",
    "        print(f\"  Positions shape: {positions.shape}\")\n",
    "        print(f\"  Forces shape: {forces.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Data not found in {data_dir}\")\n",
    "        return None\n",
    "    \n",
    "    N_samples = len(energy)\n",
    "    \n",
    "    # Normalize energies\n",
    "    energy_scaler = MinMaxScaler((-1, 1))\n",
    "    if energy.ndim == 1:\n",
    "        energy = energy.reshape(-1, 1)\n",
    "    energy_scaled = energy_scaler.fit_transform(energy).flatten()\n",
    "    \n",
    "    # Normalize forces (H atoms only)\n",
    "    forces_H = forces[:, 1:, :]  # (N, 3, 3)\n",
    "    force_scaler = MinMaxScaler((-1, 1))\n",
    "    forces_flat = forces_H.reshape(-1, 1)\n",
    "    forces_scaled = force_scaler.fit_transform(forces_flat).reshape(forces_H.shape)\n",
    "    \n",
    "    # Extract H positions for equivariant model (relative to N)\n",
    "    positions_H = positions[:, 1:, :]  # (N, 3, 3)\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = {\n",
    "        \"config\": {\n",
    "            \"n_runs\": n_runs,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"n_samples\": N_samples,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        },\n",
    "        \"rotationally_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"non_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"graph_permutation_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"classical_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "    }\n",
    "    \n",
    "    # Run experiments\n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(f\"RUN {run+1}/{n_runs}\")\n",
    "        print(f\"{'='*90}\")\n",
    "        \n",
    "        run_seed = 42 + run * 100\n",
    "        \n",
    "        # Train/test split\n",
    "        rng = np.random.default_rng(run_seed)\n",
    "        indices = np.arange(N_samples)\n",
    "        rng.shuffle(indices)\n",
    "        \n",
    "        n_train = int(0.8 * N_samples)\n",
    "        indices_train = indices[:n_train]\n",
    "        indices_test = indices[n_train:]\n",
    "        \n",
    "        print(f\"  Train: {len(indices_train)}, Test: {len(indices_test)}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        pos_H_train = jnp.array(positions_H[indices_train])\n",
    "        pos_H_all = jnp.array(positions_H)\n",
    "        pos_full_train = jnp.array(positions[indices_train])\n",
    "        pos_full_all = jnp.array(positions)\n",
    "        \n",
    "        E_train = jnp.array(energy_scaled[indices_train])\n",
    "        F_train = jnp.array(forces_scaled[indices_train])\n",
    "        \n",
    "        # --- 1. Rotationally Equivariant QML ---\n",
    "        print(f\"\\n[1/4] Rotationally Equivariant QML\")\n",
    "        rot_eq_model = RotationallyEquivariantQML(depth=6, rep=2, active_atoms=3, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        rot_eq_history = train_rotationally_equivariant(\n",
    "            rot_eq_model, pos_H_train, E_train, F_train,\n",
    "            n_epochs=n_epochs, lr=3e-3, wE=1.0, wF_max=5.0, warmup_frac=0.4\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        E_pred_rot = np.array(rot_eq_model.predict_energy(pos_H_all, rot_eq_model.params))\n",
    "        F_pred_rot = np.array(rot_eq_model.predict_forces(pos_H_all, rot_eq_model.params))\n",
    "        \n",
    "        rot_metrics, rot_predictions = evaluate_model(\n",
    "            E_pred_rot, F_pred_rot, energy_scaled, forces_scaled,\n",
    "            indices_test, energy_scaler, force_scaler, indices_train,\n",
    "            E_pred_rot[indices_train], F_pred_rot[indices_train],\n",
    "            energy_scaled[indices_train], forces_scaled[indices_train]\n",
    "        )\n",
    "        \n",
    "        print(f\"  Energy: MAE={rot_metrics['E_mae_Ha']:.6f} Ha, R²={rot_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={rot_metrics['F_mae']:.4f} eV/Å, R²={rot_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"rotationally_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": rot_eq_history,\n",
    "            \"metrics\": rot_metrics,\n",
    "            \"predictions\": rot_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 2. Non-Equivariant QML ---\n",
    "        print(f\"\\n[2/4] Non-Equivariant QML\")\n",
    "        neq_model = NonEquivariantQML(num_qubits=6, depth=4, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        neq_history = train_non_equivariant(\n",
    "            neq_model, pos_full_train, E_train, F_train,\n",
    "            n_epochs=n_epochs, lr=0.01, lambda_E=2.0, lambda_F=1.0\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        E_pred_neq = np.array(neq_model.vec_circuit(pos_full_all, neq_model.params))\n",
    "        \n",
    "        def neq_force_single(coords, params):\n",
    "            return -jax.grad(lambda c, p: neq_model.circuit(c, p), argnums=0)(coords, params)\n",
    "        neq_vec_force = jax.vmap(neq_force_single, (0, None), 0)\n",
    "        F_pred_neq_full = np.array(neq_vec_force(pos_full_all, neq_model.params))\n",
    "        F_pred_neq = F_pred_neq_full[:, 1:, :]\n",
    "        \n",
    "        neq_metrics, neq_predictions = evaluate_model(\n",
    "            E_pred_neq, F_pred_neq, energy_scaled, forces_scaled,\n",
    "            indices_test, energy_scaler, force_scaler, indices_train,\n",
    "            E_pred_neq[indices_train], F_pred_neq[indices_train],\n",
    "            energy_scaled[indices_train], forces_scaled[indices_train]\n",
    "        )\n",
    "        \n",
    "        print(f\"  Energy: MAE={neq_metrics['E_mae_Ha']:.6f} Ha, R²={neq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={neq_metrics['F_mae']:.4f} eV/Å, R²={neq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"non_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": neq_history,\n",
    "            \"metrics\": neq_metrics,\n",
    "            \"predictions\": neq_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 3. Graph Permutation Equivariant QML ---\n",
    "        print(f\"\\n[3/4] Graph Permutation Equivariant QML\")\n",
    "        gpe_model = GraphPermutationEquivariantQML(n_qubits=6, depth=4, seed=run_seed)\n",
    "        \n",
    "        n_epochs_energy = int(n_epochs * 0.5)\n",
    "        n_epochs_combined = int(n_epochs * 0.5)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs (2-phase)...\")\n",
    "        gpe_history = train_graph_permutation_equivariant(\n",
    "            gpe_model, pos_full_train, E_train, F_train,\n",
    "            n_epochs_energy=n_epochs_energy, n_epochs_combined=n_epochs_combined, lr=0.01\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        E_pred_gpe = np.array(gpe_model.vec_circuit(pos_full_all, gpe_model.params))\n",
    "        \n",
    "        def gpe_force_single(coords, params):\n",
    "            return -jax.grad(lambda c, p: gpe_model.circuit(c, p), argnums=0)(coords, params)\n",
    "        gpe_vec_force = jax.vmap(gpe_force_single, (0, None), 0)\n",
    "        F_pred_gpe_full = np.array(gpe_vec_force(pos_full_all, gpe_model.params))\n",
    "        F_pred_gpe = F_pred_gpe_full[:, 1:, :]\n",
    "        \n",
    "        gpe_metrics, gpe_predictions = evaluate_model(\n",
    "            E_pred_gpe, F_pred_gpe, energy_scaled, forces_scaled,\n",
    "            indices_test, energy_scaler, force_scaler, indices_train,\n",
    "            E_pred_gpe[indices_train], F_pred_gpe[indices_train],\n",
    "            energy_scaled[indices_train], forces_scaled[indices_train]\n",
    "        )\n",
    "        \n",
    "        print(f\"  Energy: MAE={gpe_metrics['E_mae_Ha']:.6f} Ha, R²={gpe_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={gpe_metrics['F_mae']:.4f} eV/Å, R²={gpe_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"graph_permutation_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": gpe_history,\n",
    "            \"metrics\": gpe_metrics,\n",
    "            \"predictions\": gpe_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 4. Classical Rotationally Equivariant NN ---\n",
    "        print(f\"\\n[4/4] Classical Rotationally Equivariant NN\")\n",
    "        classical_model = ClassicalRotationallyEquivariantNN(hidden_dims=[128, 128, 64], seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        classical_history = train_classical_equivariant(\n",
    "            classical_model, pos_full_train, E_train, F_train,\n",
    "            n_epochs=n_epochs, lr=0.003, lambda_E=1.0, lambda_F=2.0, warmup_frac=0.3\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        E_pred_classical = np.array(classical_model.vec_energy(pos_full_all, classical_model.params))\n",
    "        F_pred_classical_full = np.array(classical_model.vec_force(pos_full_all, classical_model.params))\n",
    "        F_pred_classical = F_pred_classical_full[:, 1:, :]\n",
    "        \n",
    "        classical_metrics, classical_predictions = evaluate_model(\n",
    "            E_pred_classical, F_pred_classical, energy_scaled, forces_scaled,\n",
    "            indices_test, energy_scaler, force_scaler, indices_train,\n",
    "            E_pred_classical[indices_train], F_pred_classical[indices_train],\n",
    "            energy_scaled[indices_train], forces_scaled[indices_train]\n",
    "        )\n",
    "        \n",
    "        print(f\"  Energy: MAE={classical_metrics['E_mae_Ha']:.6f} Ha, R²={classical_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={classical_metrics['F_mae']:.4f} eV/Å, R²={classical_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"classical_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": classical_history,\n",
    "            \"metrics\": classical_metrics,\n",
    "            \"predictions\": classical_predictions,\n",
    "        })\n",
    "    \n",
    "    # Compute summary statistics\n",
    "    for model_type in [\"rotationally_equivariant\", \"non_equivariant\", \"graph_permutation_equivariant\", \"classical_equivariant\"]:\n",
    "        metrics_list = [r[\"metrics\"] for r in all_results[model_type][\"runs\"]]\n",
    "        \n",
    "        summary = {}\n",
    "        for key in metrics_list[0].keys():\n",
    "            values = [m[key] for m in metrics_list]\n",
    "            summary[key] = {\n",
    "                \"mean\": float(np.mean(values)),\n",
    "                \"std\": float(np.std(values)),\n",
    "                \"min\": float(np.min(values)),\n",
    "                \"max\": float(np.max(values)),\n",
    "                \"values\": values,\n",
    "            }\n",
    "        all_results[model_type][\"metrics_summary\"] = summary\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(output_dir, \"results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    # Save numpy arrays\n",
    "    np.savez(os.path.join(output_dir, \"metrics.npz\"),\n",
    "             rot_eq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             neq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             gpe_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             classical_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"classical_equivariant\"][\"runs\"]])\n",
    "    \n",
    "    # Create plots\n",
    "    print(\"\\nGenerating comparison plots...\")\n",
    "    create_comparison_plots(all_results, output_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\n{'Metric':<15} {'Rot. Equiv. QML':<20} {'Non-Equiv. QML':<20} {'Graph Perm. QML':<20} {'Classical Equiv.':<20}\")\n",
    "    print(\"-\"*95)\n",
    "    \n",
    "    for metric in [\"E_r2\", \"E_mae_Ha\", \"F_r2\", \"F_mae\"]:\n",
    "        rot_mean = all_results[\"rotationally_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        rot_std = all_results[\"rotationally_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        neq_mean = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        neq_std = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        gpe_mean = all_results[\"graph_permutation_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        gpe_std = all_results[\"graph_permutation_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        cls_mean = all_results[\"classical_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        cls_std = all_results[\"classical_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        \n",
    "        print(f\"{metric:<15} {rot_mean:.4f}±{rot_std:.4f}       {neq_mean:.4f}±{neq_std:.4f}       \"\n",
    "              f\"{gpe_mean:.4f}±{gpe_std:.4f}       {cls_mean:.4f}±{cls_std:.4f}\")\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main(n_runs=2, n_epochs=400, output_dir=\"nh3_comparison_results\", \n",
    "         data_dir=\"eqnn_force_field_data_nh3_new\"):\n",
    "    \"\"\"\n",
    "    Main function - can be called directly from Jupyter or command line.\n",
    "    \n",
    "    Args:\n",
    "        n_runs: Number of runs for each model\n",
    "        n_epochs: Training epochs per run\n",
    "        output_dir: Directory to save results\n",
    "        data_dir: Directory containing NH₃ data (.npy files)\n",
    "    \n",
    "    Returns:\n",
    "        results dictionary\n",
    "    \"\"\"\n",
    "    return run_comparison(\n",
    "        n_runs=n_runs,\n",
    "        n_epochs=n_epochs,\n",
    "        output_dir=output_dir,\n",
    "        data_dir=data_dir\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    if 'ipykernel' in sys.modules:\n",
    "        print(\"Running in Jupyter notebook. Call main() directly with parameters:\")\n",
    "        print(\"  results = main(n_runs=2, n_epochs=400, output_dir='nh3_results', data_dir='eqnn_force_field_data_nh3_new')\")\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser(description=\"Compare Four Methods on NH₃\")\n",
    "        parser.add_argument(\"--n_runs\", type=int, default=2, help=\"Number of runs\")\n",
    "        parser.add_argument(\"--n_epochs\", type=int, default=400, help=\"Training epochs per run\")\n",
    "        parser.add_argument(\"--output_dir\", type=str, default=\"nh3_comparison_results\", help=\"Output directory\")\n",
    "        parser.add_argument(\"--data_dir\", type=str, default=\"eqnn_force_field_data_nh3_new\", help=\"Data directory\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        results = main(\n",
    "            n_runs=args.n_runs,\n",
    "            n_epochs=args.n_epochs,\n",
    "            output_dir=args.output_dir,\n",
    "            data_dir=args.data_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556993f-403c-4a9c-91db-c74ca3892fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-12-03 19:30:10,754:jax._src.xla_bridge:850: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "NH₃ Energy/Force Prediction: Four Methods Comparison\n",
      "==========================================================================================\n",
      "Methods:\n",
      "  1. Rotationally Equivariant QML (SO(3) symmetry)\n",
      "  2. Non-Equivariant QML (baseline)\n",
      "  3. Graph Permutation Equivariant QML (permutation symmetry)\n",
      "  4. Classical Rotationally Equivariant NN (E(3) invariant MLP)\n",
      "==========================================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loaded 2400 samples\n",
      "  Positions shape: (2400, 4, 3)\n",
      "  Forces shape: (2400, 4, 3)\n",
      "\n",
      "==========================================================================================\n",
      "RUN 1/1\n",
      "==========================================================================================\n",
      "  Train: 1920, Test: 480\n",
      "\n",
      "[1/4] Rotationally Equivariant QML\n",
      "  Training for 400 epochs...\n"
     ]
    }
   ],
   "source": [
    "results = main(n_runs=1, n_epochs=400, output_dir='nh3_results', data_dir='eqnn_force_field_data_nh3_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03b3f0-6760-4120-9e08-431fb6b5b9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
