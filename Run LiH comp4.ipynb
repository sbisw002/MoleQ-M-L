{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e83e544-cb59-4168-a93e-9236b82e38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Jupyter notebook. Call main() directly with parameters:\n",
      "  results = main(n_runs=2, n_epochs=50, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Comparison of Four Methods for LiH Energy/Force Prediction\n",
    "\n",
    "This script runs four methods on LiH molecular data and compares their performance.\n",
    "All results are saved to an output directory for later analysis.\n",
    "\n",
    "Methods compared:\n",
    "1. Rotationally Equivariant QML - Uses SO(3) equivariant encoding with Heisenberg observable\n",
    "2. Non-Equivariant QML - Simple QNN with basic rotations\n",
    "3. Graph Permutation Equivariant QML - Uses graph-based permutation-symmetric encoding\n",
    "4. Classical Rotationally Equivariant NN - Classical MLP on pairwise distances (E(3) invariant)\n",
    "\n",
    "Usage:\n",
    "    python run_comparison_four_methods.py --n_runs 3 --n_epochs 100 --output_dir results\n",
    "\"\"\"\n",
    "\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "from jax import numpy as jnp\n",
    "\n",
    "from jax.example_libraries import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# ROTATIONALLY EQUIVARIANT QML MODEL (SO(3))\n",
    "# =============================================================================\n",
    "\n",
    "class RotationallyEquivariantQML:\n",
    "    \"\"\"\n",
    "    Rotationally Equivariant Quantum Machine Learning model for LiH.\n",
    "    Uses SO(3) equivariant encoding with native PennyLane gates.\n",
    "    \n",
    "    Architecture features:\n",
    "    - Multiple qubits with singlet initialization\n",
    "    - Learnable head_scale and head_bias for output\n",
    "    - Proper alpha initialization in [0.5, 1.5] range\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits=6, depth=6, seed=42):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        \n",
    "        # Heisenberg observable\n",
    "        self.observable = (\n",
    "            qml.PauliX(0) @ qml.PauliX(1)\n",
    "            + qml.PauliY(0) @ qml.PauliY(1)\n",
    "            + qml.PauliZ(0) @ qml.PauliZ(1)\n",
    "        )\n",
    "        \n",
    "        self._build_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _singlet(self, wires):\n",
    "        \"\"\"Create singlet state on two qubits.\"\"\"\n",
    "        w0, w1 = wires\n",
    "        qml.Hadamard(wires=w0)\n",
    "        qml.PauliZ(wires=w0)\n",
    "        qml.PauliX(wires=w1)\n",
    "        qml.CNOT(wires=[w0, w1])\n",
    "    \n",
    "    def _equivariant_encoding(self, alpha, vec3, wire):\n",
    "        \"\"\"SO(3) equivariant encoding using qml.Rot.\"\"\"\n",
    "        r = jnp.array(vec3, dtype=jnp.float64)\n",
    "        norm = jnp.linalg.norm(r) + 1e-12\n",
    "        n = r / norm\n",
    "        theta = alpha * norm\n",
    "        qml.Rot(theta * n[0], theta * n[1], theta * n[2], wires=wire)\n",
    "    \n",
    "    def _pair_layer(self, weight, wires):\n",
    "        \"\"\"Trainable Heisenberg-like interaction.\"\"\"\n",
    "        qml.IsingXX(weight, wires=wires)\n",
    "        qml.IsingYY(weight, wires=wires)\n",
    "        qml.IsingZZ(weight, wires=wires)\n",
    "    \n",
    "    def _build_circuit(self):\n",
    "        \"\"\"Build the quantum circuit.\"\"\"\n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(coords, params):\n",
    "            \"\"\"\n",
    "            coords: (1, 3) - H position relative to Li\n",
    "            params: {\"weights\", \"alphas\", \"head_scale\", \"head_bias\"}\n",
    "            \"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            alphas = params[\"alphas\"]\n",
    "            \n",
    "            # Initialize singlets on pairs of qubits\n",
    "            for i in range(0, self.n_qubits - 1, 2):\n",
    "                self._singlet([i, i + 1])\n",
    "            \n",
    "            # Initial encoding - all qubits encode the same H position\n",
    "            for i in range(self.n_qubits):\n",
    "                self._equivariant_encoding(alphas[i, 0], coords[0], i)\n",
    "            \n",
    "            # Variational layers\n",
    "            for d in range(self.depth):\n",
    "                qml.Barrier()\n",
    "                # Even pairs\n",
    "                for i in range(0, self.n_qubits - 1, 2):\n",
    "                    self._pair_layer(weights[i, d], [i, (i + 1) % self.n_qubits])\n",
    "                # Odd pairs\n",
    "                for i in range(1, self.n_qubits, 2):\n",
    "                    self._pair_layer(weights[i, d], [i, (i + 1) % self.n_qubits])\n",
    "                # Re-encoding\n",
    "                for i in range(self.n_qubits):\n",
    "                    self._equivariant_encoding(alphas[i, d + 1], coords[0], i)\n",
    "            \n",
    "            return qml.expval(self.observable)\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, in_axes=(0, None), out_axes=0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters with proper ranges.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        # Weights: small initial values, only first row non-zero initially\n",
    "        weights = np.zeros((self.n_qubits, self.depth), dtype=np.float64)\n",
    "        weights[0] = np.random.uniform(0.0, np.pi, size=(self.depth,))\n",
    "        \n",
    "        # Alphas: in [0.5, 1.5] range for stable encoding\n",
    "        alphas = np.random.uniform(0.5, 1.5, size=(self.n_qubits, self.depth + 1))\n",
    "        \n",
    "        self.params = {\n",
    "            \"weights\": jnp.array(weights),\n",
    "            \"alphas\": jnp.array(alphas),\n",
    "            \"head_scale\": jnp.array(1.0),\n",
    "            \"head_bias\": jnp.array(0.0),\n",
    "        }\n",
    "    \n",
    "    def energy(self, coords, params):\n",
    "        \"\"\"Compute energy with head transformation.\"\"\"\n",
    "        raw = self.circuit(coords, params)\n",
    "        return params[\"head_scale\"] * raw + params[\"head_bias\"]\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# NON-EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class NonEquivariantQML:\n",
    "    \"\"\"\n",
    "    Simple non-equivariant QNN for molecular properties.\n",
    "    Uses basic rotations without symmetry preservation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=4, depth=3, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the simple QNN circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            weights = params[\"weights\"]\n",
    "            \n",
    "            # Single feature: bond length\n",
    "            dist = jnp.linalg.norm(positions[1] - positions[0])\n",
    "            \n",
    "            # Initialize\n",
    "            for i in range(num_qubits):\n",
    "                qml.RY(0.5, wires=i)\n",
    "            \n",
    "            # Simple layers\n",
    "            for layer in range(depth):\n",
    "                for i in range(num_qubits):\n",
    "                    qml.RY(weights[layer, i, 0] * dist, wires=i)\n",
    "                \n",
    "                for i in range(num_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "                \n",
    "                for i in range(num_qubits):\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "                    qml.RY(weights[layer, i, 2], wires=i)\n",
    "            \n",
    "            return qml.expval(qml.PauliZ(0) + qml.PauliZ(1) + qml.PauliZ(2) + qml.PauliZ(3))\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        weights = np.random.normal(0, 0.1, (self.depth, self.num_qubits, 3))\n",
    "        self.params = {\"weights\": jnp.array(weights)}\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# GRAPH PERMUTATION EQUIVARIANT QML MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class GraphPermutationEquivariantQML:\n",
    "    \"\"\"\n",
    "    Graph Permutation Equivariant Quantum Machine Learning model.\n",
    "    \n",
    "    Uses permutation-symmetric encoding based on graph structure:\n",
    "    - Encodes interatomic distances (permutation invariant features)\n",
    "    - Uses symmetric pooling operations\n",
    "    - Circuit structure respects graph connectivity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_qubits=4, depth=4, seed=42):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.depth = depth\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "        self._create_circuit()\n",
    "        self._init_params()\n",
    "    \n",
    "    def _create_circuit(self):\n",
    "        \"\"\"Create the graph permutation equivariant circuit.\"\"\"\n",
    "        num_qubits = self.num_qubits\n",
    "        depth = self.depth\n",
    "        \n",
    "        @qml.qnode(self.dev, interface=\"jax\", diff_method=\"backprop\")\n",
    "        def circuit(positions, params):\n",
    "            \"\"\"\n",
    "            Graph-based permutation equivariant circuit.\n",
    "            \"\"\"\n",
    "            weights = params[\"weights\"]       # (depth, num_qubits, 4)\n",
    "            edge_weights = params[\"edge_weights\"]  # (depth, num_edges, 2)\n",
    "            global_weights = params[\"global_weights\"]  # (depth, 3)\n",
    "            \n",
    "            # Extract graph features (permutation invariant)\n",
    "            n_atoms = positions.shape[0]\n",
    "            \n",
    "            # Compute pairwise distances (permutation invariant features)\n",
    "            dist_LiH = jnp.linalg.norm(positions[1] - positions[0])\n",
    "            \n",
    "            # Compute direction cosines for directional information\n",
    "            direction = (positions[1] - positions[0]) / (dist_LiH + 1e-8)\n",
    "            \n",
    "            # Symmetric aggregated features\n",
    "            center_of_mass = jnp.mean(positions, axis=0)\n",
    "            spread = jnp.std(positions)\n",
    "            \n",
    "            # Feature vector (all permutation invariant/equivariant)\n",
    "            features = jnp.array([\n",
    "                dist_LiH,\n",
    "                spread,\n",
    "                jnp.linalg.norm(center_of_mass),\n",
    "                direction[2]  # z-component for force direction\n",
    "            ])\n",
    "            \n",
    "            # === Symmetric Initial State ===\n",
    "            for i in range(num_qubits):\n",
    "                qml.Hadamard(wires=i)\n",
    "            \n",
    "            # === Graph-based Encoding Layers ===\n",
    "            for layer in range(depth):\n",
    "                # Node update\n",
    "                for i in range(num_qubits):\n",
    "                    angle_y = weights[layer, i, 0] * features[0] + weights[layer, i, 1] * features[1]\n",
    "                    angle_z = weights[layer, i, 2] * features[2] + weights[layer, i, 3] * features[3]\n",
    "                    \n",
    "                    qml.RY(angle_y, wires=i)\n",
    "                    qml.RZ(angle_z, wires=i)\n",
    "                \n",
    "                # Edge operations\n",
    "                edges = [(i, (i+1) % num_qubits) for i in range(num_qubits)]\n",
    "                \n",
    "                for e_idx, (i, j) in enumerate(edges):\n",
    "                    edge_angle = edge_weights[layer, e_idx % edge_weights.shape[1], 0] * dist_LiH\n",
    "                    \n",
    "                    qml.CNOT(wires=[i, j])\n",
    "                    qml.RZ(edge_angle, wires=j)\n",
    "                    qml.CNOT(wires=[i, j])\n",
    "                \n",
    "                # Global pooling layer\n",
    "                global_angle = global_weights[layer, 0] * dist_LiH + global_weights[layer, 1]\n",
    "                for i in range(num_qubits):\n",
    "                    qml.RY(global_angle * global_weights[layer, 2], wires=i)\n",
    "            \n",
    "            # === Permutation Symmetric Measurement ===\n",
    "            obs = sum(qml.PauliZ(i) for i in range(num_qubits))\n",
    "            return qml.expval(obs)\n",
    "        \n",
    "        self.circuit = circuit\n",
    "        self.vec_circuit = jax.vmap(circuit, (0, None), 0)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize parameters with Xavier-like initialization.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        num_edges = self.num_qubits\n",
    "        \n",
    "        limit = np.sqrt(2.0 / (self.num_qubits + 4))\n",
    "        weights = np.random.uniform(-limit, limit, (self.depth, self.num_qubits, 4))\n",
    "        edge_weights = np.random.uniform(-0.5, 0.5, (self.depth, num_edges, 2))\n",
    "        global_weights = np.random.uniform(-0.3, 0.3, (self.depth, 3))\n",
    "        \n",
    "        self.params = {\n",
    "            \"weights\": jnp.array(weights),\n",
    "            \"edge_weights\": jnp.array(edge_weights),\n",
    "            \"global_weights\": jnp.array(global_weights)\n",
    "        }\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CLASSICAL ROTATIONALLY EQUIVARIANT NN (E(3) INVARIANT)\n",
    "# =============================================================================\n",
    "\n",
    "class ClassicalRotationallyEquivariantNN:\n",
    "    \"\"\"\n",
    "    Classical Rotationally Equivariant Neural Network for LiH.\n",
    "    Uses physics-inspired E(3) invariant features with smooth activations.\n",
    "    \n",
    "    Key improvements:\n",
    "    - SiLU activation (smooth for autodiff force computation)\n",
    "    - Multiple physics-inspired features (not just raw distance)\n",
    "    - Larger network with skip connections\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dims=[128, 128, 64], seed=42):\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Physics parameters for LiH\n",
    "        self.r_eq = 1.6  # Equilibrium Li-H distance in Å\n",
    "        self.morse_alpha = 2.0\n",
    "        \n",
    "        # RBF parameters\n",
    "        self.rbf_centers = jnp.linspace(0.8, 3.0, 8)  # 8 Gaussians\n",
    "        self.rbf_width = 0.3\n",
    "        \n",
    "        # Number of features: distance + 1/r + Morse + 8 RBF = 11\n",
    "        self.n_features = 11\n",
    "        \n",
    "        self._init_params()\n",
    "        self._create_model()\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Initialize MLP parameters with Xavier initialization.\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        # Feature dimension -> hidden -> output\n",
    "        layer_sizes = [self.n_features] + self.hidden_dims + [1]\n",
    "        \n",
    "        params = {\"weights\": [], \"biases\": []}\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            fan_in = layer_sizes[i]\n",
    "            fan_out = layer_sizes[i + 1]\n",
    "            limit = np.sqrt(6.0 / (fan_in + fan_out))\n",
    "            \n",
    "            W = np.random.uniform(-limit, limit, (fan_in, fan_out))\n",
    "            b = np.zeros(fan_out)\n",
    "            \n",
    "            params[\"weights\"].append(jnp.array(W))\n",
    "            params[\"biases\"].append(jnp.array(b))\n",
    "        \n",
    "        # Skip connection weights (from input features to last hidden layer)\n",
    "        skip_dim = layer_sizes[-2]  # Last hidden layer dimension\n",
    "        params[\"skip_weight\"] = jnp.array(\n",
    "            np.random.uniform(-0.1, 0.1, (self.n_features, skip_dim))\n",
    "        )\n",
    "        \n",
    "        self.params = params\n",
    "    \n",
    "    def _create_model(self):\n",
    "        \"\"\"Create the forward pass function with physics-inspired features.\"\"\"\n",
    "        \n",
    "        def compute_features(positions):\n",
    "            \"\"\"Compute physics-inspired invariant features from positions.\"\"\"\n",
    "            # Li at index 0, H at index 1\n",
    "            r_vec = positions[1] - positions[0]\n",
    "            r = jnp.linalg.norm(r_vec) + 1e-12\n",
    "            \n",
    "            # Feature 1: Normalized distance\n",
    "            f_dist = r / 2.0  # Normalize by typical scale\n",
    "            \n",
    "            # Feature 2: Inverse distance (Coulomb-like)\n",
    "            f_inv = 1.0 / r\n",
    "            \n",
    "            # Feature 3: Morse-like term\n",
    "            f_morse = jnp.exp(-self.morse_alpha * (r - self.r_eq))\n",
    "            \n",
    "            # Features 4-11: RBF encoding (8 Gaussians)\n",
    "            f_rbf = jnp.exp(-((r - self.rbf_centers) ** 2) / (2 * self.rbf_width ** 2))\n",
    "            \n",
    "            # Concatenate all features\n",
    "            features = jnp.concatenate([\n",
    "                jnp.array([f_dist, f_inv, f_morse]),\n",
    "                f_rbf\n",
    "            ])\n",
    "            \n",
    "            return features\n",
    "        \n",
    "        def mlp_forward(x, params):\n",
    "            \"\"\"MLP forward pass with SiLU activation and skip connection.\"\"\"\n",
    "            weights = params[\"weights\"]\n",
    "            biases = params[\"biases\"]\n",
    "            skip_weight = params[\"skip_weight\"]\n",
    "            \n",
    "            h = x\n",
    "            for i in range(len(weights) - 1):\n",
    "                h = jnp.dot(h, weights[i]) + biases[i]\n",
    "                # SiLU activation: x * sigmoid(x) - smooth for autodiff!\n",
    "                h = h * jax.nn.sigmoid(h)\n",
    "                \n",
    "                # Add skip connection to last hidden layer\n",
    "                if i == len(weights) - 2:\n",
    "                    h = h + 0.1 * jnp.dot(x, skip_weight)\n",
    "            \n",
    "            # Output layer (no activation)\n",
    "            h = jnp.dot(h, weights[-1]) + biases[-1]\n",
    "            return h.squeeze(-1)\n",
    "        \n",
    "        def energy_from_positions(positions, params):\n",
    "            \"\"\"Compute energy from atomic positions.\"\"\"\n",
    "            features = compute_features(positions)\n",
    "            energy = mlp_forward(features, params)\n",
    "            return energy\n",
    "        \n",
    "        def force_from_positions(positions, params):\n",
    "            \"\"\"Compute forces as negative gradient of energy.\"\"\"\n",
    "            grad_fn = jax.grad(energy_from_positions, argnums=0)\n",
    "            return -grad_fn(positions, params)\n",
    "        \n",
    "        self.compute_features = compute_features\n",
    "        self.energy_fn = energy_from_positions\n",
    "        self.force_fn = force_from_positions\n",
    "        self.vec_energy = jax.vmap(energy_from_positions, (0, None), 0)\n",
    "        self.vec_force = jax.vmap(force_from_positions, (0, None), 0)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self.params = params\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def train_rotationally_equivariant(model, data_train, E_train, F_train, data_test, E_test, F_test,\n",
    "                                    n_epochs=200, lr=3e-3, wE=1.0, wF_max=5.0, warmup_frac=0.4):\n",
    "    \"\"\"Train the rotationally equivariant QML model with force warmup curriculum.\"\"\"\n",
    "    warmup_epochs = int(n_epochs * warmup_frac)\n",
    "    \n",
    "    def raw_energy(coords, params):\n",
    "        \"\"\"Raw circuit output.\"\"\"\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    vec_raw_energy = jax.vmap(raw_energy, (0, None), 0)\n",
    "    \n",
    "    def vec_force_fn(coords_batch, params):\n",
    "        \"\"\"Compute forces as -grad(energy).\"\"\"\n",
    "        def single_force(coords):\n",
    "            grad_fn = jax.grad(raw_energy, argnums=0)\n",
    "            return -grad_fn(coords, params)\n",
    "        return jax.vmap(single_force)(coords_batch)\n",
    "    \n",
    "    @jax.jit\n",
    "    def loss_fn(params, coords, E_target, F_target, wF):\n",
    "        # Energy with head transformation\n",
    "        E_raw = vec_raw_energy(coords, params)\n",
    "        E_pred = params[\"head_scale\"] * E_raw + params[\"head_bias\"]\n",
    "        L_E = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        # Forces (scaled by head_scale)\n",
    "        F_raw = vec_force_fn(coords, params)\n",
    "        F_pred = params[\"head_scale\"] * F_raw\n",
    "        F_pred_z = F_pred[:, 0, 2]  # H atom z-component\n",
    "        L_F = jnp.mean((F_pred_z - F_target) ** 2)\n",
    "        \n",
    "        # Handle NaNs\n",
    "        L_E = jnp.where(jnp.isnan(L_E), 1.0, L_E)\n",
    "        L_F = jnp.where(jnp.isnan(L_F), 1.0, L_F)\n",
    "        \n",
    "        return wE * L_E + wF * L_F, (L_E, L_F)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Warmup curriculum: gradually increase force weight\n",
    "        if epoch < warmup_epochs:\n",
    "            wF = wF_max * (epoch / warmup_epochs)\n",
    "        else:\n",
    "            wF = wF_max\n",
    "        \n",
    "        (loss, (L_E, L_F)), grads = jax.value_and_grad(loss_fn, has_aux=True)(\n",
    "            get_params(opt_state), data_train, E_train, F_train, wF\n",
    "        )\n",
    "        \n",
    "        # Gradient clipping\n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(g**2) for g in jax.tree.leaves(grads)))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm), grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_raw_test = np.array(vec_raw_energy(data_test, test_params))\n",
    "            E_pred_test = float(test_params[\"head_scale\"]) * E_raw_test + float(test_params[\"head_bias\"])\n",
    "            F_raw_test = np.array(vec_force_fn(data_test, test_params))[:, 0, 2]\n",
    "            F_pred_test = float(test_params[\"head_scale\"]) * F_raw_test\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_non_equivariant(model, pos_train, E_train, F_train, pos_test, E_test, F_test,\n",
    "                          n_epochs=200, lr=0.01, lambda_E=2.0, lambda_F=1.0):\n",
    "    \"\"\"Train the non-equivariant QML model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_z = F_pred_full[:, 1, 2]\n",
    "        F_loss = jnp.mean((F_pred_z - F_target) ** 2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), pos_train, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(pos_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(pos_test, test_params))[:, 1, 2]\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_graph_permutation_equivariant(model, pos_train, E_train, F_train, pos_test, E_test, F_test,\n",
    "                                         n_epochs=200, lr=0.01, lambda_E=1.5, lambda_F=1.5):\n",
    "    \"\"\"Train the graph permutation equivariant QML model.\"\"\"\n",
    "    \n",
    "    def energy_single(coords, params):\n",
    "        return model.circuit(coords, params)\n",
    "    \n",
    "    def force_single(coords, params):\n",
    "        grad_fn = jax.grad(energy_single, argnums=0)\n",
    "        return -grad_fn(coords, params)\n",
    "    \n",
    "    vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "    \n",
    "    @jax.jit\n",
    "    def combined_loss(params, positions, E_target, F_target):\n",
    "        E_pred = model.vec_circuit(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = vec_force(positions, params)\n",
    "        F_pred_z = F_pred_full[:, 1, 2]\n",
    "        F_loss = jnp.mean((F_pred_z - F_target) ** 2)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        total_loss = lambda_E * E_loss + lambda_F * F_loss\n",
    "        return total_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(combined_loss, has_aux=True)(\n",
    "            get_params(opt_state), pos_train, E_train, F_train\n",
    "        )\n",
    "        \n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 10.0:\n",
    "            grads = jax.tree.map(lambda g: g * (10.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_circuit(pos_test, test_params))\n",
    "            F_pred_test = np.array(vec_force(pos_test, test_params))[:, 1, 2]\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_classical_equivariant(model, pos_train, E_train, F_train, pos_test, E_test, F_test,\n",
    "                                 n_epochs=200, lr=3e-3, wE=1.0, wF_max=2.0, warmup_frac=0.3):\n",
    "    \"\"\"\n",
    "    Train the classical rotationally equivariant NN with two-phase training.\n",
    "    \n",
    "    Phase 1 (warmup): Energy-only training to establish good features\n",
    "    Phase 2: Combined energy + forces with gradual force weight ramp\n",
    "    \"\"\"\n",
    "    warmup_epochs = int(n_epochs * warmup_frac)\n",
    "    \n",
    "    def huber_loss(pred, target, delta=0.5):\n",
    "        \"\"\"Huber loss - robust to outliers.\"\"\"\n",
    "        diff = pred - target\n",
    "        abs_diff = jnp.abs(diff)\n",
    "        return jnp.mean(jnp.where(abs_diff <= delta, \n",
    "                                   0.5 * diff**2, \n",
    "                                   delta * (abs_diff - 0.5 * delta)))\n",
    "    \n",
    "    @jax.jit\n",
    "    def loss_fn(params, positions, E_target, F_target, wF):\n",
    "        E_pred = model.vec_energy(positions, params)\n",
    "        E_loss = jnp.mean((E_pred - E_target) ** 2)\n",
    "        \n",
    "        F_pred_full = model.vec_force(positions, params)\n",
    "        F_pred_z = F_pred_full[:, 1, 2]\n",
    "        F_loss = huber_loss(F_pred_z, F_target, delta=0.5)\n",
    "        \n",
    "        E_loss = jnp.where(jnp.isnan(E_loss), 1.0, E_loss)\n",
    "        F_loss = jnp.where(jnp.isnan(F_loss), 1.0, F_loss)\n",
    "        \n",
    "        return wE * E_loss + wF * F_loss, (E_loss, F_loss)\n",
    "    \n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr)\n",
    "    opt_state = opt_init(model.params)\n",
    "    \n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"test_E_loss\": [], \"test_F_loss\": []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Two-phase training\n",
    "        if epoch < warmup_epochs:\n",
    "            wF = 0.0  # Energy-only warmup\n",
    "        else:\n",
    "            phase2_progress = (epoch - warmup_epochs) / max(1, (n_epochs - warmup_epochs) / 2)\n",
    "            wF = min(wF_max, wF_max * phase2_progress)\n",
    "        \n",
    "        (loss, (E_loss, F_loss)), grads = jax.value_and_grad(loss_fn, has_aux=True)(\n",
    "            get_params(opt_state), pos_train, E_train, F_train, wF\n",
    "        )\n",
    "        \n",
    "        # Gradient clipping\n",
    "        grad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree.leaves(grads) if g is not None))\n",
    "        if grad_norm > 5.0:\n",
    "            grads = jax.tree.map(lambda g: g * (5.0 / grad_norm) if g is not None else g, grads)\n",
    "        \n",
    "        opt_state = opt_update(epoch, grads, opt_state)\n",
    "        \n",
    "        if (epoch + 1) % max(1, n_epochs // 20) == 0:\n",
    "            test_params = get_params(opt_state)\n",
    "            E_pred_test = np.array(model.vec_energy(pos_test, test_params))\n",
    "            F_pred_test = np.array(model.vec_force(pos_test, test_params))[:, 1, 2]\n",
    "            \n",
    "            E_test_loss = np.mean((E_pred_test - np.array(E_test)) ** 2)\n",
    "            F_test_loss = np.mean((F_pred_test - np.array(F_test)) ** 2)\n",
    "            \n",
    "            history[\"epoch\"].append(epoch + 1)\n",
    "            history[\"train_loss\"].append(float(loss))\n",
    "            history[\"test_E_loss\"].append(float(E_test_loss))\n",
    "            history[\"test_F_loss\"].append(float(F_test_loss))\n",
    "    \n",
    "    model.set_params(get_params(opt_state))\n",
    "    return history\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "def load_lih_data(data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Load LiH molecular data.\"\"\"\n",
    "    energy = np.load(os.path.join(data_dir, \"Energy.npy\"))\n",
    "    forces = np.load(os.path.join(data_dir, \"Forces.npy\"))\n",
    "    positions = np.load(os.path.join(data_dir, \"Positions.npy\"))\n",
    "    \n",
    "    return energy, forces, positions\n",
    "\n",
    "\n",
    "def prepare_data(energy, forces, positions, test_split=0.2, seed=42):\n",
    "    \"\"\"Prepare and scale data for training.\"\"\"\n",
    "    shape = positions.shape\n",
    "    \n",
    "    # Scale energy\n",
    "    energy_scaler = MinMaxScaler((-1, 1))\n",
    "    if energy.ndim == 1:\n",
    "        energy = energy.reshape(-1, 1)\n",
    "    energy_scaled = energy_scaler.fit_transform(energy).flatten()\n",
    "    \n",
    "    # Center molecule positions\n",
    "    n_atoms_total = positions.shape[1]\n",
    "    positions_centered = np.zeros((shape[0], n_atoms_total - 1, 3))\n",
    "    positions_centered[:, 0, :] = positions[:, 1, :] - positions[:, 0, :]\n",
    "    \n",
    "    # Scale forces (z-component of H atom)\n",
    "    forces_H = forces[:, 1:, :]\n",
    "    force_scaler = MinMaxScaler((-1, 1))\n",
    "    forces_z_only = forces_H[:, 0, 2].reshape(-1, 1)\n",
    "    forces_z_scaled = force_scaler.fit_transform(forces_z_only).flatten()\n",
    "    \n",
    "    forces_scaled = np.zeros_like(forces_H)\n",
    "    forces_scaled[:, 0, 2] = forces_z_scaled\n",
    "    \n",
    "    # Train/test split\n",
    "    np.random.seed(seed)\n",
    "    n_samples = shape[0]\n",
    "    indices_train = np.random.choice(np.arange(n_samples), size=int((1-test_split) * n_samples), replace=False)\n",
    "    indices_test = np.setdiff1d(np.arange(n_samples), indices_train)\n",
    "    \n",
    "    data = {\n",
    "        \"energy_scaler\": energy_scaler,\n",
    "        \"force_scaler\": force_scaler,\n",
    "        \"energy_scaled\": energy_scaled,\n",
    "        \"forces_scaled\": forces_scaled,\n",
    "        \"positions_centered\": positions_centered,\n",
    "        \"positions_raw\": positions,\n",
    "        \"forces_H\": forces_H,\n",
    "        \"indices_train\": indices_train,\n",
    "        \"indices_test\": indices_test,\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_model(model, data, model_type=\"rotationally_equivariant\"):\n",
    "    \"\"\"Evaluate model and compute metrics.\"\"\"\n",
    "    \n",
    "    positions_centered = data[\"positions_centered\"]\n",
    "    positions_raw = data[\"positions_raw\"]\n",
    "    energy_scaled = data[\"energy_scaled\"]\n",
    "    forces_z_scaled = data[\"forces_scaled\"][:, 0, 2]\n",
    "    energy_scaler = data[\"energy_scaler\"]\n",
    "    force_scaler = data[\"force_scaler\"]\n",
    "    indices_train = data[\"indices_train\"]\n",
    "    indices_test = data[\"indices_test\"]\n",
    "    forces_H = data[\"forces_H\"]\n",
    "    \n",
    "    if model_type == \"rotationally_equivariant\":\n",
    "        # Apply head transformation for rotationally equivariant model\n",
    "        params = model.params\n",
    "        E_raw = np.array(model.vec_circuit(jnp.array(positions_centered), params))\n",
    "        E_pred_scaled = float(params[\"head_scale\"]) * E_raw + float(params[\"head_bias\"])\n",
    "        \n",
    "        def raw_energy(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(raw_energy, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_raw = np.array(vec_force(jnp.array(positions_centered), params))\n",
    "        F_pred_z_scaled = float(params[\"head_scale\"]) * F_raw[:, 0, 2]\n",
    "        \n",
    "    elif model_type == \"classical_equivariant\":\n",
    "        E_pred_scaled = np.array(model.vec_energy(jnp.array(positions_raw), model.params))\n",
    "        F_pred_all = np.array(model.vec_force(jnp.array(positions_raw), model.params))\n",
    "        F_pred_z_scaled = F_pred_all[:, 1, 2]\n",
    "        \n",
    "    else:\n",
    "        # For non-equivariant and graph permutation equivariant QML\n",
    "        E_pred_scaled = np.array(model.vec_circuit(jnp.array(positions_raw), model.params))\n",
    "        \n",
    "        def energy_single(coords, params):\n",
    "            return model.circuit(coords, params)\n",
    "        def force_single(coords, params):\n",
    "            return -jax.grad(energy_single, argnums=0)(coords, params)\n",
    "        vec_force = jax.vmap(force_single, (0, None), 0)\n",
    "        \n",
    "        F_pred_all = np.array(vec_force(jnp.array(positions_raw), model.params))\n",
    "        F_pred_z_scaled = F_pred_all[:, 1, 2]\n",
    "    \n",
    "    # Post-correction for energy\n",
    "    def corr_E(E, a, b, c):\n",
    "        return a * E**2 + b * E + c\n",
    "    \n",
    "    try:\n",
    "        popt_E, _ = curve_fit(corr_E, E_pred_scaled[indices_train], energy_scaled[indices_train])\n",
    "        E_pred_corrected = corr_E(E_pred_scaled, *popt_E)\n",
    "    except:\n",
    "        E_pred_corrected = E_pred_scaled\n",
    "    \n",
    "    # Post-correction for force\n",
    "    try:\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(F_pred_z_scaled[indices_train].reshape(-1, 1), forces_z_scaled[indices_train])\n",
    "        F_pred_corrected = lr_model.predict(F_pred_z_scaled.reshape(-1, 1)).flatten()\n",
    "    except:\n",
    "        F_pred_corrected = F_pred_z_scaled\n",
    "    \n",
    "    # Inverse transform\n",
    "    E_pred_original = energy_scaler.inverse_transform(E_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    F_pred_original = force_scaler.inverse_transform(F_pred_corrected.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    E_true_original = energy_scaler.inverse_transform(energy_scaled.reshape(-1, 1)).flatten()\n",
    "    F_true_original = forces_H[:, 0, 2]\n",
    "    \n",
    "    # Compute metrics on test set\n",
    "    E_mae = np.mean(np.abs(E_pred_original[indices_test] - E_true_original[indices_test]))\n",
    "    E_rmse = np.sqrt(np.mean((E_pred_original[indices_test] - E_true_original[indices_test]) ** 2))\n",
    "    E_r2 = 1 - np.sum((E_pred_original[indices_test] - E_true_original[indices_test])**2) / \\\n",
    "               np.sum((E_true_original[indices_test] - E_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    F_mae = np.mean(np.abs(F_pred_original[indices_test] - F_true_original[indices_test]))\n",
    "    F_rmse = np.sqrt(np.mean((F_pred_original[indices_test] - F_true_original[indices_test]) ** 2))\n",
    "    F_r2 = 1 - np.sum((F_pred_original[indices_test] - F_true_original[indices_test])**2) / \\\n",
    "               np.sum((F_true_original[indices_test] - F_true_original[indices_test].mean())**2)\n",
    "    \n",
    "    metrics = {\n",
    "        \"E_mae_Ha\": float(E_mae),\n",
    "        \"E_mae_eV\": float(E_mae * 27.2114),\n",
    "        \"E_rmse_Ha\": float(E_rmse),\n",
    "        \"E_rmse_eV\": float(E_rmse * 27.2114),\n",
    "        \"E_r2\": float(E_r2),\n",
    "        \"F_mae\": float(F_mae),\n",
    "        \"F_rmse\": float(F_rmse),\n",
    "        \"F_r2\": float(F_r2),\n",
    "    }\n",
    "    \n",
    "    predictions = {\n",
    "        \"E_pred\": E_pred_original.tolist(),\n",
    "        \"E_true\": E_true_original.tolist(),\n",
    "        \"F_pred\": F_pred_original.tolist(),\n",
    "        \"F_true\": F_true_original.tolist(),\n",
    "        \"indices_test\": indices_test.tolist(),\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTTING\n",
    "# =============================================================================\n",
    "\n",
    "def create_comparison_plots(all_results, output_dir):\n",
    "    \"\"\"Create comparison plots for all four methods.\"\"\"\n",
    "    \n",
    "    methods = [\"rotationally_equivariant\", \"non_equivariant\", \"graph_permutation_equivariant\", \"classical_equivariant\"]\n",
    "    method_names = [\"Rot. Equiv. QML\", \"Non-Equiv. QML\", \"Graph Perm. QML\", \"Classical Equiv. NN\"]\n",
    "    colors = [\"#2ecc71\", \"#e74c3c\", \"#3498db\", \"#9b59b6\"]\n",
    "    \n",
    "    # =====================================================\n",
    "    # Figure 1: Training curves (2x2)\n",
    "    # =====================================================\n",
    "    fig1, axes1 = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes1 = axes1.flatten()\n",
    "    \n",
    "    for idx, (method, name, color) in enumerate(zip(methods, method_names, colors)):\n",
    "        ax = axes1[idx]\n",
    "        \n",
    "        if len(all_results[method][\"runs\"]) > 0:\n",
    "            history = all_results[method][\"runs\"][0][\"history\"]\n",
    "            epochs = history[\"epoch\"]\n",
    "            \n",
    "            ax.plot(epochs, history[\"train_loss\"], '-', color=color, lw=2, label='Train Loss')\n",
    "            ax.plot(epochs, history[\"test_E_loss\"], '--', color=color, lw=2, alpha=0.7, label='Test E Loss')\n",
    "            ax.plot(epochs, history[\"test_F_loss\"], ':', color=color, lw=2, alpha=0.7, label='Test F Loss')\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title(f'{name}\\nTraining Curves')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # =====================================================\n",
    "    # Figure 2: Bar chart comparisons\n",
    "    # =====================================================\n",
    "    fig2, axes2 = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    x_pos = np.arange(len(methods))\n",
    "    \n",
    "    # Energy R² comparison\n",
    "    ax = axes2[0]\n",
    "    E_r2_means = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"mean\"] for m in methods]\n",
    "    E_r2_stds = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(x_pos, E_r2_means, yerr=E_r2_stds, color=colors, alpha=0.8, capsize=5)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('Energy R²')\n",
    "    ax.set_title('Energy Prediction R²')\n",
    "    ax.set_ylim([0, 1.15])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, E_r2_means):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{mean:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Force R² comparison\n",
    "    ax = axes2[1]\n",
    "    F_r2_means = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"mean\"] for m in methods]\n",
    "    F_r2_stds = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars = ax.bar(x_pos, F_r2_means, yerr=F_r2_stds, color=colors, alpha=0.8, capsize=5)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('Force R²')\n",
    "    ax.set_title('Force Prediction R²')\n",
    "    ax.set_ylim([0, 1.15])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, mean in zip(bars, F_r2_means):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{mean:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # MAE comparison\n",
    "    ax = axes2[2]\n",
    "    width = 0.35\n",
    "    E_mae_means = [all_results[m][\"metrics_summary\"][\"E_mae_Ha\"][\"mean\"] * 1000 for m in methods]\n",
    "    F_mae_means = [all_results[m][\"metrics_summary\"][\"F_mae\"][\"mean\"] for m in methods]\n",
    "    \n",
    "    bars1 = ax.bar(x_pos - width/2, E_mae_means, width, color=colors, alpha=0.6, label='Energy MAE (mHa)')\n",
    "    bars2 = ax.bar(x_pos + width/2, F_mae_means, width, color=colors, alpha=1.0, hatch='//', label='Force MAE (eV/Å)')\n",
    "    \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(method_names, fontsize=9, rotation=15, ha='right')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title('Mean Absolute Errors')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'metrics_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # =====================================================\n",
    "    # Figure 3: Scatter plots (2x4)\n",
    "    # =====================================================\n",
    "    fig3, axes3 = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    for idx, (method, name, color) in enumerate(zip(methods, method_names, colors)):\n",
    "        if len(all_results[method][\"runs\"]) > 0:\n",
    "            predictions = all_results[method][\"runs\"][0][\"predictions\"]\n",
    "            indices_test = predictions[\"indices_test\"]\n",
    "            \n",
    "            E_pred = np.array(predictions[\"E_pred\"])[indices_test]\n",
    "            E_true = np.array(predictions[\"E_true\"])[indices_test]\n",
    "            F_pred = np.array(predictions[\"F_pred\"])[indices_test]\n",
    "            F_true = np.array(predictions[\"F_true\"])[indices_test]\n",
    "            \n",
    "            metrics = all_results[method][\"runs\"][0][\"metrics\"]\n",
    "            \n",
    "            # Energy scatter\n",
    "            ax = axes3[0, idx]\n",
    "            ax.scatter(E_true, E_pred, c=color, alpha=0.6, s=20)\n",
    "            lims = [min(E_true.min(), E_pred.min()), max(E_true.max(), E_pred.max())]\n",
    "            ax.plot(lims, lims, 'k--', lw=2)\n",
    "            ax.set_xlabel('True Energy (Ha)')\n",
    "            ax.set_ylabel('Predicted Energy (Ha)')\n",
    "            ax.set_title(f'{name}\\nE R²={metrics[\"E_r2\"]:.3f}')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Force scatter\n",
    "            ax = axes3[1, idx]\n",
    "            ax.scatter(F_true, F_pred, c=color, alpha=0.6, s=20)\n",
    "            lims = [min(F_true.min(), F_pred.min()), max(F_true.max(), F_pred.max())]\n",
    "            ax.plot(lims, lims, 'k--', lw=2)\n",
    "            ax.set_xlabel('True Force Z (eV/Å)')\n",
    "            ax.set_ylabel('Predicted Force Z (eV/Å)')\n",
    "            ax.set_title(f'{name}\\nF R²={metrics[\"F_r2\"]:.3f}')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'predictions_scatter.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # =====================================================\n",
    "    # Figure 4: Summary comparison plot\n",
    "    # =====================================================\n",
    "    fig4, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    # Create grouped bar chart for R² values\n",
    "    width = 0.35\n",
    "    x = np.arange(len(methods))\n",
    "    \n",
    "    E_r2 = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"mean\"] for m in methods]\n",
    "    F_r2 = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"mean\"] for m in methods]\n",
    "    E_r2_err = [all_results[m][\"metrics_summary\"][\"E_r2\"][\"std\"] for m in methods]\n",
    "    F_r2_err = [all_results[m][\"metrics_summary\"][\"F_r2\"][\"std\"] for m in methods]\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, E_r2, width, yerr=E_r2_err, label='Energy R²', \n",
    "                   color='steelblue', alpha=0.8, capsize=4)\n",
    "    bars2 = ax.bar(x + width/2, F_r2, width, yerr=F_r2_err, label='Force R²', \n",
    "                   color='coral', alpha=0.8, capsize=4)\n",
    "    \n",
    "    ax.set_ylabel('R² Score')\n",
    "    ax.set_title('Method Comparison: Energy vs Force Prediction Performance')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(method_names, fontsize=10)\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'summary_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Plots saved to: {output_dir}/\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "def run_comparison(n_runs=3, n_epochs=100, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"Run comparison between all four methods.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*90)\n",
    "    print(\"LiH Energy/Force Prediction: Four Methods Comparison\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"Methods:\")\n",
    "    print(\"  1. Rotationally Equivariant QML (SO(3) symmetry)\")\n",
    "    print(\"  2. Non-Equivariant QML (baseline)\")\n",
    "    print(\"  3. Graph Permutation Equivariant QML (permutation symmetry)\")\n",
    "    print(\"  4. Classical Rotationally Equivariant NN (E(3) invariant MLP)\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nLoading data...\")\n",
    "    try:\n",
    "        energy, forces, positions = load_lih_data(data_dir)\n",
    "        print(f\"  Loaded {len(energy)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ERROR: Data not found in {data_dir}\")\n",
    "        print(\"  Please ensure the LiH data files are available\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    data = prepare_data(energy, forces, positions)\n",
    "    print(f\"  Train: {len(data['indices_train'])}, Test: {len(data['indices_test'])}\")\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = {\n",
    "        \"config\": {\n",
    "            \"n_runs\": n_runs,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        },\n",
    "        \"rotationally_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"non_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"graph_permutation_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "        \"classical_equivariant\": {\"runs\": [], \"metrics_summary\": {}},\n",
    "    }\n",
    "    \n",
    "    # Prepare training data\n",
    "    E_train = data[\"energy_scaled\"][data[\"indices_train\"]]\n",
    "    E_test = data[\"energy_scaled\"][data[\"indices_test\"]]\n",
    "    \n",
    "    # For rotationally equivariant QML model\n",
    "    data_train_eq = jnp.array(data[\"positions_centered\"][data[\"indices_train\"]])\n",
    "    data_test_eq = jnp.array(data[\"positions_centered\"][data[\"indices_test\"]])\n",
    "    # Extract z-component of H atom force (index 0 since centered on Li)\n",
    "    F_train_eq = data[\"forces_scaled\"][data[\"indices_train\"], 0, 2]\n",
    "    F_test_eq = data[\"forces_scaled\"][data[\"indices_test\"], 0, 2]\n",
    "    \n",
    "    # For non-equivariant, graph permutation, and classical models\n",
    "    pos_train_neq = jnp.array(data[\"positions_raw\"][data[\"indices_train\"]])\n",
    "    pos_test_neq = jnp.array(data[\"positions_raw\"][data[\"indices_test\"]])\n",
    "    F_train_neq = data[\"forces_scaled\"][data[\"indices_train\"], 0, 2]\n",
    "    F_test_neq = data[\"forces_scaled\"][data[\"indices_test\"], 0, 2]\n",
    "    \n",
    "    # Run experiments\n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(f\"RUN {run+1}/{n_runs}\")\n",
    "        print(f\"{'='*90}\")\n",
    "        \n",
    "        run_seed = 42 + run * 100\n",
    "        \n",
    "        # --- 1. Rotationally Equivariant QML Model ---\n",
    "        print(f\"\\n[1/4] Rotationally Equivariant QML\")\n",
    "        eq_model = RotationallyEquivariantQML(n_qubits=6, depth=6, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        eq_history = train_rotationally_equivariant(\n",
    "            eq_model, data_train_eq, E_train, F_train_eq,\n",
    "            data_test_eq, E_test, F_test_eq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        eq_metrics, eq_predictions = evaluate_model(eq_model, data, \"rotationally_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={eq_metrics['E_mae_Ha']:.6f} Ha, R²={eq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={eq_metrics['F_mae']:.4f} eV/Å, R²={eq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"rotationally_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": eq_history,\n",
    "            \"metrics\": eq_metrics,\n",
    "            \"predictions\": eq_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 2. Non-Equivariant QML Model ---\n",
    "        print(f\"\\n[2/4] Non-Equivariant QML\")\n",
    "        neq_model = NonEquivariantQML(num_qubits=4, depth=3, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        neq_history = train_non_equivariant(\n",
    "            neq_model, pos_train_neq, E_train, F_train_neq,\n",
    "            pos_test_neq, E_test, F_test_neq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        neq_metrics, neq_predictions = evaluate_model(neq_model, data, \"non_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={neq_metrics['E_mae_Ha']:.6f} Ha, R²={neq_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={neq_metrics['F_mae']:.4f} eV/Å, R²={neq_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"non_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": neq_history,\n",
    "            \"metrics\": neq_metrics,\n",
    "            \"predictions\": neq_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 3. Graph Permutation Equivariant QML Model ---\n",
    "        print(f\"\\n[3/4] Graph Permutation Equivariant QML\")\n",
    "        gpe_model = GraphPermutationEquivariantQML(num_qubits=4, depth=4, seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        gpe_history = train_graph_permutation_equivariant(\n",
    "            gpe_model, pos_train_neq, E_train, F_train_neq,\n",
    "            pos_test_neq, E_test, F_test_neq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        gpe_metrics, gpe_predictions = evaluate_model(gpe_model, data, \"graph_permutation_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={gpe_metrics['E_mae_Ha']:.6f} Ha, R²={gpe_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={gpe_metrics['F_mae']:.4f} eV/Å, R²={gpe_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"graph_permutation_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": gpe_history,\n",
    "            \"metrics\": gpe_metrics,\n",
    "            \"predictions\": gpe_predictions,\n",
    "        })\n",
    "        \n",
    "        # --- 4. Classical Rotationally Equivariant NN ---\n",
    "        print(f\"\\n[4/4] Classical Rotationally Equivariant NN\")\n",
    "        classical_model = ClassicalRotationallyEquivariantNN(hidden_dims=[128, 128, 64], seed=run_seed)\n",
    "        \n",
    "        print(f\"  Training for {n_epochs} epochs...\")\n",
    "        classical_history = train_classical_equivariant(\n",
    "            classical_model, pos_train_neq, E_train, F_train_neq,\n",
    "            pos_test_neq, E_test, F_test_neq, n_epochs=n_epochs\n",
    "        )\n",
    "        \n",
    "        print(f\"  Evaluating...\")\n",
    "        classical_metrics, classical_predictions = evaluate_model(classical_model, data, \"classical_equivariant\")\n",
    "        \n",
    "        print(f\"  Energy: MAE={classical_metrics['E_mae_Ha']:.6f} Ha, R²={classical_metrics['E_r2']:.4f}\")\n",
    "        print(f\"  Force:  MAE={classical_metrics['F_mae']:.4f} eV/Å, R²={classical_metrics['F_r2']:.4f}\")\n",
    "        \n",
    "        all_results[\"classical_equivariant\"][\"runs\"].append({\n",
    "            \"run_id\": run,\n",
    "            \"seed\": run_seed,\n",
    "            \"history\": classical_history,\n",
    "            \"metrics\": classical_metrics,\n",
    "            \"predictions\": classical_predictions,\n",
    "        })\n",
    "    \n",
    "    # Compute summary statistics\n",
    "    for model_type in [\"rotationally_equivariant\", \"non_equivariant\", \"graph_permutation_equivariant\", \"classical_equivariant\"]:\n",
    "        metrics_list = [r[\"metrics\"] for r in all_results[model_type][\"runs\"]]\n",
    "        \n",
    "        summary = {}\n",
    "        for key in metrics_list[0].keys():\n",
    "            values = [m[key] for m in metrics_list]\n",
    "            summary[key] = {\n",
    "                \"mean\": float(np.mean(values)),\n",
    "                \"std\": float(np.std(values)),\n",
    "                \"min\": float(np.min(values)),\n",
    "                \"max\": float(np.max(values)),\n",
    "                \"values\": values,\n",
    "            }\n",
    "        all_results[model_type][\"metrics_summary\"] = summary\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(output_dir, \"results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nResults saved to: {results_path}\")\n",
    "    \n",
    "    # Save numpy arrays for easy loading\n",
    "    np.savez(os.path.join(output_dir, \"metrics.npz\"),\n",
    "             # Rotationally Equivariant QML\n",
    "             rot_eq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             rot_eq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"rotationally_equivariant\"][\"runs\"]],\n",
    "             # Non-Equivariant QML\n",
    "             neq_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             neq_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"non_equivariant\"][\"runs\"]],\n",
    "             # Graph Permutation Equivariant QML\n",
    "             gpe_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             gpe_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"graph_permutation_equivariant\"][\"runs\"]],\n",
    "             # Classical Equivariant NN\n",
    "             classical_E_r2=[r[\"metrics\"][\"E_r2\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_F_r2=[r[\"metrics\"][\"F_r2\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_E_mae=[r[\"metrics\"][\"E_mae_Ha\"] for r in all_results[\"classical_equivariant\"][\"runs\"]],\n",
    "             classical_F_mae=[r[\"metrics\"][\"F_mae\"] for r in all_results[\"classical_equivariant\"][\"runs\"]])\n",
    "    \n",
    "    # Create plots\n",
    "    print(\"\\nGenerating comparison plots...\")\n",
    "    create_comparison_plots(all_results, output_dir)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\n{'Metric':<15} {'Rot. Equiv. QML':<20} {'Non-Equiv. QML':<20} {'Graph Perm. QML':<20} {'Classical Equiv.':<20}\")\n",
    "    print(\"-\"*95)\n",
    "    \n",
    "    for metric in [\"E_r2\", \"E_mae_Ha\", \"F_r2\", \"F_mae\"]:\n",
    "        rot_mean = all_results[\"rotationally_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        rot_std = all_results[\"rotationally_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        neq_mean = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        neq_std = all_results[\"non_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        gpe_mean = all_results[\"graph_permutation_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        gpe_std = all_results[\"graph_permutation_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        cls_mean = all_results[\"classical_equivariant\"][\"metrics_summary\"][metric][\"mean\"]\n",
    "        cls_std = all_results[\"classical_equivariant\"][\"metrics_summary\"][metric][\"std\"]\n",
    "        \n",
    "        print(f\"{metric:<15} {rot_mean:.4f}±{rot_std:.4f}       {neq_mean:.4f}±{neq_std:.4f}       \"\n",
    "              f\"{gpe_mean:.4f}±{gpe_std:.4f}       {cls_mean:.4f}±{cls_std:.4f}\")\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main(n_runs=2, n_epochs=50, output_dir=\"lih_comparison_results\", data_dir=\"eqnn_force_field_data_LiH\"):\n",
    "    \"\"\"\n",
    "    Main function - can be called directly from Jupyter or command line.\n",
    "    \n",
    "    Args:\n",
    "        n_runs: Number of runs for each model\n",
    "        n_epochs: Training epochs per run\n",
    "        output_dir: Directory to save results\n",
    "        data_dir: Directory containing LiH data (.npy files)\n",
    "    \n",
    "    Returns:\n",
    "        results dictionary\n",
    "    \"\"\"\n",
    "    return run_comparison(\n",
    "        n_runs=n_runs,\n",
    "        n_epochs=n_epochs,\n",
    "        output_dir=output_dir,\n",
    "        data_dir=data_dir\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Check if running in Jupyter\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        print(\"Running in Jupyter notebook. Call main() directly with parameters:\")\n",
    "        print(\"  results = main(n_runs=2, n_epochs=50, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')\")\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser(description=\"Compare Four Methods on LiH\")\n",
    "        parser.add_argument(\"--n_runs\", type=int, default=2, help=\"Number of runs\")\n",
    "        parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"Training epochs per run\")\n",
    "        parser.add_argument(\"--output_dir\", type=str, default=\"lih_comparison_results\", help=\"Output directory\")\n",
    "        parser.add_argument(\"--data_dir\", type=str, default=\"eqnn_force_field_data_LiH\", help=\"Data directory\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        results = main(\n",
    "            n_runs=args.n_runs,\n",
    "            n_epochs=args.n_epochs,\n",
    "            output_dir=args.output_dir,\n",
    "            data_dir=args.data_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd38dd8-248b-47be-9f1f-199fe6a766fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "LiH Energy/Force Prediction: Four Methods Comparison\n",
      "==========================================================================================\n",
      "Methods:\n",
      "  1. Rotationally Equivariant QML (SO(3) symmetry)\n",
      "  2. Non-Equivariant QML (baseline)\n",
      "  3. Graph Permutation Equivariant QML (permutation symmetry)\n",
      "  4. Classical Rotationally Equivariant NN (E(3) invariant MLP)\n",
      "==========================================================================================\n",
      "\n",
      "Loading data...\n",
      "  Loaded 2400 samples\n",
      "  Train: 1920, Test: 480\n",
      "\n",
      "==========================================================================================\n",
      "RUN 1/1\n",
      "==========================================================================================\n",
      "\n",
      "[1/4] Rotationally Equivariant QML\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.027774 Ha, R²=0.9963\n",
      "  Force:  MAE=0.8454 eV/Å, R²=0.9937\n",
      "\n",
      "[2/4] Non-Equivariant QML\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.026232 Ha, R²=0.9979\n",
      "  Force:  MAE=2.5130 eV/Å, R²=0.9584\n",
      "\n",
      "[3/4] Graph Permutation Equivariant QML\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.033164 Ha, R²=0.9964\n",
      "  Force:  MAE=2.5839 eV/Å, R²=0.9548\n",
      "\n",
      "[4/4] Classical Rotationally Equivariant NN\n",
      "  Training for 200 epochs...\n",
      "  Evaluating...\n",
      "  Energy: MAE=0.023289 Ha, R²=0.9978\n",
      "  Force:  MAE=0.9685 eV/Å, R²=0.9930\n",
      "\n",
      "Results saved to: lih_results/results.json\n",
      "\n",
      "Generating comparison plots...\n",
      "  Plots saved to: lih_results/\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "Metric          Rot. Equiv. QML      Non-Equiv. QML       Graph Perm. QML      Classical Equiv.    \n",
      "-----------------------------------------------------------------------------------------------\n",
      "E_r2            0.9963±0.0000       0.9979±0.0000       0.9964±0.0000       0.9978±0.0000\n",
      "E_mae_Ha        0.0278±0.0000       0.0262±0.0000       0.0332±0.0000       0.0233±0.0000\n",
      "F_r2            0.9937±0.0000       0.9584±0.0000       0.9548±0.0000       0.9930±0.0000\n",
      "F_mae           0.8454±0.0000       2.5130±0.0000       2.5839±0.0000       0.9685±0.0000\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "results = main(n_runs=1, n_epochs=200, output_dir='lih_results', data_dir='eqnn_force_field_data_LiH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f57e7-af00-43e6-9136-7424e9769035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
